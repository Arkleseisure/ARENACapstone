{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f003b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformer import SyntheticSequenceDataset, TinyTransformer, generate_square_subsequent_mask\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from train_model import train_model, test_model, rl_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba019af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e263363c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\source\\repos\\Arkleseisure\\SimulatorToyModel\\.toysimulatorvenve\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.num_heads is odd\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model param count: 451\n",
      "Model count by layer:\n",
      "('pos_emb', Parameter containing:\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0', requires_grad=True))\n",
      "('embedding.weight', Parameter containing:\n",
      "tensor([[ 0.5077,  0.5392, -0.9084],\n",
      "        [-0.7566,  0.7558, -0.6125],\n",
      "        [-0.1811, -1.5659,  0.5352],\n",
      "        [-0.3716, -1.5232, -0.8678],\n",
      "        [-0.5672,  1.5776, -1.7446],\n",
      "        [ 0.9225,  0.0418,  0.3847]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.6608,  0.1597, -0.5351],\n",
      "        [ 0.6106,  0.2427,  0.3646],\n",
      "        [ 0.1721,  0.3995,  0.1437],\n",
      "        [ 0.1274, -0.5166,  0.2849],\n",
      "        [-0.6803, -0.6468,  0.6665],\n",
      "        [ 0.1093, -0.0715,  0.6282],\n",
      "        [-0.5804, -0.3331, -0.1550],\n",
      "        [ 0.4310,  0.3538, -0.3077],\n",
      "        [-0.2547, -0.2200, -0.2944]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4025,  0.0582,  0.4926],\n",
      "        [ 0.0649,  0.1169,  0.5584],\n",
      "        [ 0.1416,  0.2433, -0.2134]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.5338,  0.4054,  0.0316],\n",
      "        [-0.4773, -0.0581,  0.2743]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.bias', Parameter containing:\n",
      "tensor([ 0.5139, -0.3292], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6778,  0.0168],\n",
      "        [ 0.4708, -0.2566],\n",
      "        [-0.5267,  0.0123]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.bias', Parameter containing:\n",
      "tensor([-0.3545,  0.6283,  0.2343], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.6608,  0.1597, -0.5351],\n",
      "        [ 0.6106,  0.2427,  0.3646],\n",
      "        [ 0.1721,  0.3995,  0.1437],\n",
      "        [ 0.1274, -0.5166,  0.2849],\n",
      "        [-0.6803, -0.6468,  0.6665],\n",
      "        [ 0.1093, -0.0715,  0.6282],\n",
      "        [-0.5804, -0.3331, -0.1550],\n",
      "        [ 0.4310,  0.3538, -0.3077],\n",
      "        [-0.2547, -0.2200, -0.2944]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4025,  0.0582,  0.4926],\n",
      "        [ 0.0649,  0.1169,  0.5584],\n",
      "        [ 0.1416,  0.2433, -0.2134]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.5338,  0.4054,  0.0316],\n",
      "        [-0.4773, -0.0581,  0.2743]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.bias', Parameter containing:\n",
      "tensor([ 0.5139, -0.3292], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6778,  0.0168],\n",
      "        [ 0.4708, -0.2566],\n",
      "        [-0.5267,  0.0123]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.bias', Parameter containing:\n",
      "tensor([-0.3545,  0.6283,  0.2343], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.6608,  0.1597, -0.5351],\n",
      "        [ 0.6106,  0.2427,  0.3646],\n",
      "        [ 0.1721,  0.3995,  0.1437],\n",
      "        [ 0.1274, -0.5166,  0.2849],\n",
      "        [-0.6803, -0.6468,  0.6665],\n",
      "        [ 0.1093, -0.0715,  0.6282],\n",
      "        [-0.5804, -0.3331, -0.1550],\n",
      "        [ 0.4310,  0.3538, -0.3077],\n",
      "        [-0.2547, -0.2200, -0.2944]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.2.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4025,  0.0582,  0.4926],\n",
      "        [ 0.0649,  0.1169,  0.5584],\n",
      "        [ 0.1416,  0.2433, -0.2134]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.5338,  0.4054,  0.0316],\n",
      "        [-0.4773, -0.0581,  0.2743]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.linear1.bias', Parameter containing:\n",
      "tensor([ 0.5139, -0.3292], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6778,  0.0168],\n",
      "        [ 0.4708, -0.2566],\n",
      "        [-0.5267,  0.0123]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.linear2.bias', Parameter containing:\n",
      "tensor([-0.3545,  0.6283,  0.2343], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.2.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.6608,  0.1597, -0.5351],\n",
      "        [ 0.6106,  0.2427,  0.3646],\n",
      "        [ 0.1721,  0.3995,  0.1437],\n",
      "        [ 0.1274, -0.5166,  0.2849],\n",
      "        [-0.6803, -0.6468,  0.6665],\n",
      "        [ 0.1093, -0.0715,  0.6282],\n",
      "        [-0.5804, -0.3331, -0.1550],\n",
      "        [ 0.4310,  0.3538, -0.3077],\n",
      "        [-0.2547, -0.2200, -0.2944]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.3.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4025,  0.0582,  0.4926],\n",
      "        [ 0.0649,  0.1169,  0.5584],\n",
      "        [ 0.1416,  0.2433, -0.2134]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.5338,  0.4054,  0.0316],\n",
      "        [-0.4773, -0.0581,  0.2743]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.linear1.bias', Parameter containing:\n",
      "tensor([ 0.5139, -0.3292], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6778,  0.0168],\n",
      "        [ 0.4708, -0.2566],\n",
      "        [-0.5267,  0.0123]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.linear2.bias', Parameter containing:\n",
      "tensor([-0.3545,  0.6283,  0.2343], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.3.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[-0.6608,  0.1597, -0.5351],\n",
      "        [ 0.6106,  0.2427,  0.3646],\n",
      "        [ 0.1721,  0.3995,  0.1437],\n",
      "        [ 0.1274, -0.5166,  0.2849],\n",
      "        [-0.6803, -0.6468,  0.6665],\n",
      "        [ 0.1093, -0.0715,  0.6282],\n",
      "        [-0.5804, -0.3331, -0.1550],\n",
      "        [ 0.4310,  0.3538, -0.3077],\n",
      "        [-0.2547, -0.2200, -0.2944]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.4.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.4025,  0.0582,  0.4926],\n",
      "        [ 0.0649,  0.1169,  0.5584],\n",
      "        [ 0.1416,  0.2433, -0.2134]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.linear1.weight', Parameter containing:\n",
      "tensor([[ 0.5338,  0.4054,  0.0316],\n",
      "        [-0.4773, -0.0581,  0.2743]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.linear1.bias', Parameter containing:\n",
      "tensor([ 0.5139, -0.3292], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6778,  0.0168],\n",
      "        [ 0.4708, -0.2566],\n",
      "        [-0.5267,  0.0123]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.linear2.bias', Parameter containing:\n",
      "tensor([-0.3545,  0.6283,  0.2343], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.4.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('head.weight', Parameter containing:\n",
      "tensor([[-0.2463, -0.5503,  0.3199],\n",
      "        [ 0.5025, -0.5299,  0.3554],\n",
      "        [ 0.4206, -0.0352,  0.1836],\n",
      "        [-0.0095,  0.0239,  0.1079],\n",
      "        [ 0.1136, -0.4012,  0.5344],\n",
      "        [-0.4191, -0.2185, -0.5670]], device='cuda:0', requires_grad=True))\n",
      "('head.bias', Parameter containing:\n",
      "tensor([ 0.3536, -0.1281,  0.2749,  0.2866, -0.5663, -0.2288], device='cuda:0',\n",
      "       requires_grad=True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.37768346071243286:  85%|████████▌ | 851/1000 [00:25<00:04, 35.52it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "rl_batch_size = 1024\n",
    "\n",
    "vocab_size = 6\n",
    "seq_len = 8\n",
    "epochs = 1000\n",
    "batch_size = 1024\n",
    "d_model = 3\n",
    "nhead = 3\n",
    "num_layers = 5\n",
    "dim_ff = 2\n",
    "lr = 1e-2\n",
    "model = train_model(vocab_size, seq_len, epochs, batch_size, d_model, nhead, num_layers, dim_ff, lr, device, verbose=True)\n",
    "base_model = TinyTransformer(vocab_size, d_model, nhead, num_layers, dim_ff, seq_len)   # same arch as base_model\n",
    "base_model.load_state_dict(model.state_dict())  # copy weights\n",
    "for p in base_model.parameters():\n",
    "    p.requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1424bbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-4): 5 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-13.0758638381958, 2.4244611263275146, 7.17145299911499, 7.2258830070495605, 7.179135322570801, -1.0330541133880615]\n",
      "probs 0: [5.238367517534925e-10, 0.002824238035827875, 0.3254570960998535, 0.34366270899772644, 0.3279670178890228, 8.898600208340213e-05]\n",
      "logits 1: [0.003916025161743164, 4.443919658660889, -0.9081064462661743, -1.2702842950820923, -1.05265212059021, -3.457655429840088]\n",
      "probs 1: [0.011516012251377106, 0.9762725234031677, 0.00462610786780715, 0.0032205041497945786, 0.004003504756838083, 0.0003613770822994411]\n",
      "logits 2: [-1.8692744970321655, 5.485661506652832, -1.0068680047988892, -1.4572348594665527, -1.2105464935302734, -3.0292930603027344]\n",
      "probs 2: [0.0006365284789353609, 0.995465099811554, 0.0015078438445925713, 0.0009610909037292004, 0.0012299851514399052, 0.00019953922310378402]\n",
      "logits 3: [13.108548164367676, 8.302845001220703, -10.735075950622559, -11.718568801879883, -11.143760681152344, -5.774971961975098]\n",
      "probs 3: [0.991883397102356, 0.008116528391838074, 4.37830709187903e-11, 1.6374962150123018e-11, 2.9094917447514135e-11, 6.243844108411167e-09]\n",
      "logits 4: [-0.9149681329727173, 5.696475505828857, -1.6562485694885254, -2.144061803817749, -1.8748931884765625, -3.2023239135742188]\n",
      "probs 4: [0.0013408256927505136, 0.9969784021377563, 0.0006389078916981816, 0.00039226876106113195, 0.000513430975843221, 0.0001361400936730206]\n",
      "logits 5: [-0.23103880882263184, 5.845409393310547, -2.1196141242980957, -2.634026527404785, -2.3488543033599854, -3.3264622688293457]\n",
      "probs 5: [0.0022889208048582077, 0.9967789053916931, 0.00034628453431650996, 0.0002070268092211336, 0.0002753438602667302, 0.0001035871246131137]\n",
      "logits 6: [10.378543853759766, 7.9057488441467285, -9.071741104125977, -9.970991134643555, -9.450138092041016, -5.267423152923584]\n",
      "probs 6: [0.9222123622894287, 0.07778748869895935, 3.293666006598528e-09, 1.3401091347731153e-09, 2.2560244783420558e-09, 1.4786780866415938e-07]\n",
      "input : [5, 4, 1, 0, 0, 1, 0]\n",
      "preds : [3, 1, 0, 1, 1, 0, 1]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-13.05765438079834, 2.445420026779175, 7.143080711364746, 7.194915294647217, 7.149448394775391, -1.0353233814239502]\n",
      "probs 0: [5.494616983625633e-10, 0.002970549277961254, 0.32584044337272644, 0.34317564964294434, 0.32792189717292786, 9.144692739937454e-05]\n",
      "logits 1: [7.089932441711426, 7.326054573059082, -6.972432613372803, -7.758943557739258, -7.30817985534668, -4.662198066711426]\n",
      "probs 1: [0.4412403702735901, 0.5587554574012756, 3.4472114407435583e-07, 1.569966343595297e-07, 2.464078363573208e-07, 3.4736801808321616e-06]\n",
      "logits 2: [7.441775321960449, 7.391315937042236, -7.20009183883667, -7.999023914337158, -7.540598392486572, -4.726752281188965]\n",
      "probs 2: [0.5126105546951294, 0.4873862862586975, 2.24339430587861e-07, 1.0090982272004112e-07, 1.5959713550728338e-07, 2.661111693669227e-06]\n",
      "logits 3: [7.253257751464844, 7.356431007385254, -7.078189849853516, -7.8704752922058105, -7.416151523590088, -4.692159175872803]\n",
      "probs 3: [0.47422781586647034, 0.525768518447876, 2.830859955338383e-07, 1.2818388483992749e-07, 2.0190324789837177e-07, 3.07722007164557e-06]\n",
      "logits 4: [7.35906982421875, 7.376034736633301, -7.146633625030518, -7.942652702331543, -7.486024379730225, -4.711574554443359]\n",
      "probs 4: [0.49575722217559814, 0.5042394399642944, 2.486118546585203e-07, 1.121541615134447e-07, 1.7706257438021566e-07, 2.8382771688484354e-06]\n",
      "logits 5: [7.406232833862305, 7.384753704071045, -7.177122592926025, -7.974803447723389, -7.51715087890625, -4.720229148864746]\n",
      "probs 5: [0.5053679347038269, 0.49462881684303284, 2.3449688058008178e-07, 1.0561078767068466e-07, 1.6690312065748003e-07, 2.7362270884623285e-06]\n",
      "logits 6: [7.316471099853516, 7.368149280548096, -7.119085788726807, -7.913602828979492, -7.457901477813721, -4.703757286071777]\n",
      "probs 6: [0.4870816469192505, 0.5129148960113525, 2.620107295570051e-07, 1.183763345125044e-07, 1.8671244106371887e-07, 2.932801635324722e-06]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [3, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.2857142857142857\n",
      "logits 0: [-12.573134422302246, 2.3034491539001465, 7.048333644866943, 7.108816146850586, 7.062243461608887, -1.1383527517318726]\n",
      "probs 0: [9.754465013500635e-10, 0.0028185206465423107, 0.3241144120693207, 0.3443226218223572, 0.32865428924560547, 9.021229925565422e-05]\n",
      "logits 1: [14.584626197814941, 8.129783630371094, -11.268531799316406, -12.254497528076172, -11.670014381408691, -6.073033332824707]\n",
      "probs 1: [0.9984295964241028, 0.001570416963659227, 5.907912180302954e-12, 2.20411644664964e-12, 3.9543212454473675e-12, 1.0661294069791438e-09]\n",
      "logits 2: [14.79403305053711, 8.364145278930664, -11.58851432800293, -12.603593826293945, -12.004719734191895, -6.099535942077637]\n",
      "probs 2: [0.9983899593353271, 0.0016100354259833694, 3.479408601514411e-12, 1.2608459198579225e-12, 2.29482817297455e-12, 8.420502628503357e-10]\n",
      "logits 3: [-0.5592467188835144, 5.7741594314575195, -1.897460699081421, -2.3991332054138184, -2.1216297149658203, -3.266876220703125]\n",
      "probs 3: [0.0017706366488710046, 0.9969943761825562, 0.0004644621512852609, 0.00028123994707129896, 0.00037118897307664156, 0.00011809208081103861]\n",
      "logits 4: [14.559222221374512, 8.403814315795898, -11.51511001586914, -12.531143188476562, -11.933197975158691, -6.051381587982178]\n",
      "probs 4: [0.9978825449943542, 0.0021174822468310595, 4.733042516941177e-12, 1.7134949058597582e-12, 3.1157854074592706e-12, 1.1168841407283026e-09]\n",
      "logits 5: [14.586478233337402, 8.40233039855957, -11.52657413482666, -12.54284381866455, -11.944634437561035, -6.05678129196167]\n",
      "probs 5: [0.9979423880577087, 0.0020576154347509146, 4.553558918818368e-12, 1.6481268389975656e-12, 2.9977101530243022e-12, 1.081065459374031e-09]\n",
      "logits 6: [-2.565364360809326, 5.329620361328125, -0.5310572385787964, -0.9538573026657104, -0.7236807346343994, -2.903219223022461]\n",
      "probs 6: [0.00036975869443267584, 0.992354154586792, 0.002827526768669486, 0.0018526227213442326, 0.002332123462110758, 0.0002637484285514802]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [3, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.2857142857142857\n",
      "logits 0: [-13.010919570922852, 2.4834017753601074, 7.0851826667785645, 7.132110118865967, 7.089134693145752, -1.0421113967895508]\n",
      "probs 0: [6.113934358786821e-10, 0.003276568604633212, 0.3265482187271118, 0.34223753213882446, 0.32784128189086914, 9.645140380598605e-05]\n",
      "logits 1: [14.728815078735352, 8.384990692138672, -11.577400207519531, -12.59383487701416, -11.994725227355957, -6.085562229156494]\n",
      "probs 1: [0.9982454776763916, 0.0017544840229675174, 3.754855367604781e-12, 1.3588164881478404e-12, 2.473721748275093e-12, 9.113146903771963e-10]\n",
      "logits 2: [14.827987670898438, 8.300506591796875, -11.54449462890625, -12.553003311157227, -11.95690631866455, -6.110029220581055]\n",
      "probs 2: [0.9985394477844238, 0.0014605493051931262, 3.515132412576505e-12, 1.2821886564637341e-12, 2.3272015824832293e-12, 8.055639488802058e-10]\n",
      "logits 3: [-0.8030195832252502, 5.720975399017334, -1.7322089672088623, -2.2243897914886475, -1.9525954723358154, -3.2226357460021973]\n",
      "probs 3: [0.001463407650589943, 0.9970117807388306, 0.0005778612103313208, 0.00035324186319485307, 0.0004635652876459062, 0.00013017850869800895]\n",
      "logits 4: [14.825078964233398, 8.33995246887207, -11.580343246459961, -12.593191146850586, -11.995147705078125, -6.107058525085449]\n",
      "probs 4: [0.9984763264656067, 0.0015236425679177046, 3.4010153634328466e-12, 1.2351916364727877e-12, 2.2462667576689244e-12, 8.10263744988049e-10]\n",
      "logits 5: [14.388504981994629, 8.406373977661133, -11.43694019317627, -12.450749397277832, -11.854801177978516, -6.017972946166992]\n",
      "probs 5: [0.99748295545578, 0.002517091576009989, 6.068162031885871e-12, 2.2017368397214687e-12, 3.9956072304947465e-12, 1.3692548206378774e-09]\n",
      "logits 6: [1.198109745979309, 6.150947570800781, -3.0825138092041016, -3.6518757343292236, -3.3335485458374023, -3.586209535598755]\n",
      "probs 6: [0.00701178889721632, 0.9927022457122803, 9.700132795842364e-05, 5.4891748732188717e-05, 7.546658162027597e-05, 5.8617257309379056e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-12.913344383239746, 2.3120803833007812, 7.200778007507324, 7.265303134918213, 7.214929103851318, -1.0715601444244385]\n",
      "probs 0: [5.953508797063023e-10, 0.002438322640955448, 0.32376179099082947, 0.3453412652015686, 0.328375905752182, 8.271697879536077e-05]\n",
      "logits 1: [-1.552840232849121, 4.12300443649292, 0.1295369267463684, -0.17410719394683838, 0.00800807774066925, -3.1739895343780518]\n",
      "probs 1: [0.0032568685710430145, 0.9501414895057678, 0.017516499385237694, 0.012929342687129974, 0.015512008219957352, 0.0006437895935960114]\n",
      "logits 2: [-0.4640190601348877, 5.794874668121338, -1.9619569778442383, -2.4673304557800293, -2.1875996589660645, -3.2841625213623047]\n",
      "probs 2: [0.0019075337331742048, 0.9969545602798462, 0.0004265070310793817, 0.0002573032397776842, 0.00034035395947284997, 0.00011368412378942594]\n",
      "logits 3: [14.234496116638184, 7.98121452331543, -10.963072776794434, -11.927387237548828, -11.35473346710205, -6.013890743255615]\n",
      "probs 3: [0.9980795383453369, 0.0019204341806471348, 1.1376273187369002e-11, 4.337137420040715e-12, 7.689603294391834e-12, 1.6047326800716633e-09]\n",
      "logits 4: [-0.5729620456695557, 5.771173477172852, -1.8881688117980957, -2.389307975769043, -2.1121249198913574, -3.2643866539001465]\n",
      "probs 4: [0.001751747797243297, 0.9969985485076904, 0.0004702019796241075, 0.00028486718656495214, 0.0003758560342248529, 0.00011874092160724103]\n",
      "logits 5: [-0.08343589305877686, 5.877320289611816, -2.2193970680236816, -2.7395238876342773, -2.450909376144409, -3.3532674312591553]\n",
      "probs 5: [0.0025692181661725044, 0.9966083765029907, 0.0003035041445400566, 0.00018041666771750897, 0.00024077988928183913, 9.766323637450114e-05]\n",
      "logits 6: [12.273269653320312, 8.195125579833984, -10.239157676696777, -11.198405265808105, -10.639412879943848, -5.618841171264648]\n",
      "probs 6: [0.983343243598938, 0.016656726598739624, 1.6431672689165566e-10, 6.296305837816263e-11, 1.1011688783035822e-10, 1.6682461634331958e-08]\n",
      "input : [5, 4, 1, 0, 1, 1, 1]\n",
      "preds : [3, 1, 1, 1, 1, 1, 1]\n",
      "reward: 0.8571428571428571\n",
      "logits 0: [-12.747749328613281, 2.6222710609436035, 6.829923629760742, 6.857556343078613, 6.824839115142822, -1.0849072933197021]\n",
      "probs 0: [1.0349270329612636e-09, 0.0048980629071593285, 0.3291429877281189, 0.33836495876312256, 0.3274737298488617, 0.0001202311905217357]\n",
      "logits 1: [7.118053436279297, 7.331294059753418, -6.9906511306762695, -7.778156757354736, -7.326779365539551, -4.667356014251709]\n",
      "probs 1: [0.44688910245895386, 0.5531067848205566, 3.333244933401147e-07, 1.5165532829541917e-07, 2.3817084127131238e-07, 3.4029978905891767e-06]\n",
      "logits 2: [6.933187961578369, 7.29677152633667, -6.870814323425293, -7.651767730712891, -7.204427719116211, -4.63345193862915]\n",
      "probs 2: [0.4100904166698456, 0.58990478515625, 4.148372738654871e-07, 1.8998251505308872e-07, 2.971603692003555e-07, 3.886437752953498e-06]\n",
      "logits 3: [7.052951812744141, 7.319157600402832, -6.948469161987305, -7.733669757843018, -7.283713340759277, -4.6554155349731445]\n",
      "probs 3: [0.4338369071483612, 0.5661587119102478, 3.6023558891429275e-07, 1.642775231402993e-07, 2.576273345766822e-07, 3.568183501556632e-06]\n",
      "logits 4: [7.174411773681641, 7.3417840003967285, -7.027151584625244, -7.816651344299316, -7.364044666290283, -4.677694320678711]\n",
      "probs 4: [0.45825254917144775, 0.5417435169219971, 3.1149011192610487e-07, 1.4143884641271143e-07, 2.2239933628043218e-07, 3.264380893597263e-06]\n",
      "logits 5: [7.136094093322754, 7.334654808044434, -7.0023369789123535, -7.790481090545654, -7.338710308074951, -4.670665264129639]\n",
      "probs 5: [0.45052045583724976, 0.5494754910469055, 3.2619078638163046e-07, 1.483151237380298e-07, 2.3301669216380105e-07, 3.3581825391593156e-06]\n",
      "logits 6: [7.2124528884887695, 7.348855018615723, -7.051779747009277, -7.842624664306641, -7.389188289642334, -4.684673309326172]\n",
      "probs 6: [0.46595045924186707, 0.5340456962585449, 2.974830692892283e-07, 1.3489710681824363e-07, 2.1228912316928472e-07, 3.1730980936117703e-06]\n",
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-4): 5 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-12.944008827209473, 2.52532696723938, 7.014038562774658, 7.055325031280518, 7.0152907371521, -1.0525884628295898]\n",
      "probs 0: [7.035994009640945e-10, 0.003677671542391181, 0.3273373246192932, 0.34113478660583496, 0.3277474641799927, 0.00010273151565343142]\n",
      "logits 1: [-1.3359739780426025, 4.1671528816223145, -0.014487743377685547, -0.3262241780757904, -0.13918916881084442, -3.2135403156280518]\n",
      "probs 1: [0.003899933071807027, 0.9572710394859314, 0.014620811678469181, 0.010704983957111835, 0.012906672433018684, 0.0005965412128716707]\n",
      "logits 2: [-1.8568613529205322, 5.488426685333252, -1.0153369903564453, -1.4661933183670044, -1.219211459159851, -3.0315423011779785]\n",
      "probs 2: [0.0006427230546250939, 0.995501697063446, 0.0014910538448020816, 0.000949924229644239, 0.0012160508194938302, 0.00019854844140354544]\n",
      "logits 3: [14.29405689239502, 8.404413223266602, -11.390507698059082, -12.402710914611816, -11.808036804199219, -5.999695777893066]\n",
      "probs 3: [0.9972397089004517, 0.0027603222988545895, 6.984493278877624e-12, 2.5382864213274736e-12, 4.600496632950479e-12, 1.5322682012097744e-09]\n",
      "logits 4: [-2.4465389251708984, 5.356396675109863, -0.6124111413955688, -1.039932370185852, -0.8069302439689636, -2.924731969833374]\n",
      "probs 4: [0.00040569735574536026, 0.9930566549301147, 0.0025395324919372797, 0.0016560890944674611, 0.0020906205754727125, 0.0002514927473384887]\n",
      "logits 5: [-0.6743795275688171, 5.7490692138671875, -1.8194395303726196, -2.3166322708129883, -2.0418238639831543, -3.2459802627563477]\n",
      "probs 5: [0.001618209178559482, 0.9970178604125977, 0.0005149219068698585, 0.00031319388654083014, 0.0004122503742109984, 0.00012365239672362804]\n",
      "logits 6: [14.60184383392334, 8.4013090133667, -11.532864570617676, -12.549245834350586, -11.950896263122559, -6.059835910797119]\n",
      "probs 6: [0.997975766658783, 0.002024239394813776, 4.456155496684877e-12, 1.6126940277985669e-12, 2.933671318025577e-12, 1.0613687706495512e-09]\n",
      "input : [5, 4, 1, 1, 1, 1, 0]\n",
      "preds : [3, 1, 0, 1, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-13.005013465881348, 2.327951431274414, 7.229073524475098, 7.293182373046875, 7.242465019226074, -1.0527374744415283]\n",
      "probs 0: [5.28272314781475e-10, 0.002409236738458276, 0.3238990902900696, 0.3453439772129059, 0.3282657563686371, 8.197190618375316e-05]\n",
      "logits 1: [7.282310485839844, 7.361819267272949, -7.096987724304199, -7.890298366546631, -7.435340881347656, -4.6974897384643555]\n",
      "probs 1: [0.48013150691986084, 0.5198648571968079, 2.7321866014062834e-07, 1.2358908918486122e-07, 1.9478946455819823e-07, 3.0102257824182743e-06]\n",
      "logits 2: [7.3931684494018555, 7.3823394775390625, -7.168678283691406, -7.9658989906311035, -7.508529186248779, -4.717832088470459]\n",
      "probs 2: [0.5027055740356445, 0.4972911477088928, 2.3833290185848455e-07, 1.0738786926367538e-07, 1.696636644510363e-07, 2.764223836493329e-06]\n",
      "logits 3: [7.084013938903809, 7.324951171875, -6.968598365783691, -7.754898548126221, -7.304264545440674, -4.661112308502197]\n",
      "probs 3: [0.4400535523891449, 0.5599422454833984, 3.471630805051973e-07, 1.5814224241239572e-07, 2.481737055859412e-07, 3.488688435027143e-06]\n",
      "logits 4: [7.353615760803223, 7.375025749206543, -7.143106937408447, -7.938933849334717, -7.482425689697266, -4.710573673248291]\n",
      "probs 4: [0.4946460425853729, 0.5053505897521973, 2.5029240191543067e-07, 1.1293403190393292e-07, 1.7827218812271894e-07, 2.8502529403340304e-06]\n",
      "logits 5: [7.316580772399902, 7.368169784545898, -7.1191558837890625, -7.913676738739014, -7.457973480224609, -4.70377779006958]\n",
      "probs 5: [0.4871039092540741, 0.5128926038742065, 2.6197562874585856e-07, 1.1835990676445363e-07, 1.8668707468805223e-07, 2.93255675387627e-06]\n",
      "logits 6: [7.462413787841797, 7.3951239585876465, -7.21342658996582, -8.01308536529541, -7.554211616516113, -4.7305402755737305]\n",
      "probs 6: [0.5168144702911377, 0.4831823706626892, 2.186241658819199e-07, 9.826769797882662e-08, 1.5548808107723744e-07, 2.618194912429317e-06]\n",
      "input : [5, 4, 1, 1, 0, 1, 0]\n",
      "preds : [3, 1, 1, 0, 1, 1, 1]\n",
      "reward: 0.7142857142857142\n",
      "logits 0: [-13.051459312438965, 2.344409942626953, 7.235466957092285, 7.298431396484375, 7.24796199798584, -1.0426872968673706]\n",
      "probs 0: [5.014155757265826e-10, 0.002435226459056139, 0.32411444187164307, 0.3451783359050751, 0.3281897008419037, 8.232687832787633e-05]\n",
      "logits 1: [6.829556465148926, 7.277342796325684, -6.803564071655273, -7.580835819244385, -7.135762691497803, -4.614450931549072]\n",
      "probs 1: [0.38988518714904785, 0.6101096272468567, 4.6789423890913895e-07, 2.1507139535970055e-07, 3.356416584665567e-07, 4.177026767138159e-06]\n",
      "logits 2: [7.285714149475098, 7.362450122833252, -7.099189758300781, -7.8926215171813965, -7.4375901222229, -4.698113918304443]\n",
      "probs 2: [0.48082369565963745, 0.519172728061676, 2.7208315600546484e-07, 1.2306041696774628e-07, 1.9397066353121772e-07, 3.002447556355037e-06]\n",
      "logits 3: [7.583057403564453, 7.417333602905273, -7.2913312911987305, -8.095230102539062, -7.633738040924072, -4.752685546875]\n",
      "probs 3: [0.5413348078727722, 0.45866233110427856, 1.8775911314605764e-07, 8.403733176010064e-08, 1.333201709030618e-07, 2.3775019144522958e-06]\n",
      "logits 4: [6.190008163452148, 7.156260967254639, -6.3874287605285645, -7.141848087310791, -6.710825443267822, -4.497259140014648]\n",
      "probs 4: [0.27562573552131653, 0.7243659496307373, 9.506229616818018e-07, 4.470624048735772e-07, 6.879532747916528e-07, 6.293588285188889e-06]\n",
      "logits 5: [7.315796852111816, 7.368024826049805, -7.118649005889893, -7.913142204284668, -7.457456588745117, -4.703634262084961]\n",
      "probs 5: [0.4869442284107208, 0.513052225112915, 2.6222812721243827e-07, 1.1847727421354648e-07, 1.8686880309815024e-07, 2.934314352387446e-06]\n",
      "logits 6: [7.353989601135254, 7.375095367431641, -7.1433491706848145, -7.939188480377197, -7.482672214508057, -4.710642337799072]\n",
      "probs 6: [0.49472206830978394, 0.5052745342254639, 2.5017692451001494e-07, 1.1288042855994718e-07, 1.7818911146605387e-07, 2.8494328034867067e-06]\n",
      "input : [5, 4, 0, 0, 1, 1, 1]\n",
      "preds : [3, 1, 1, 1, 1, 1, 1]\n",
      "reward: 0.8571428571428571\n",
      "logits 0: [-12.769453048706055, 2.302929401397705, 7.141491889953613, 7.204917907714844, 7.155875205993652, -1.1001453399658203]\n",
      "probs 0: [7.296055426486703e-10, 0.0025641336105763912, 0.32381847500801086, 0.3450223207473755, 0.32850971817970276, 8.531080675311387e-05]\n",
      "logits 1: [7.072726249694824, 7.322846412658691, -6.9612836837768555, -7.7471842765808105, -7.2967963218688965, -4.659041881561279]\n",
      "probs 1: [0.4377920627593994, 0.5622036457061768, 3.518639459798578e-07, 1.6034768179906678e-07, 2.515727999252704e-07, 3.5174334698240273e-06]\n",
      "logits 2: [7.183921813964844, 7.343552112579346, -7.0333099365234375, -7.823145866394043, -7.370331764221191, -4.679439067840576]\n",
      "probs 2: [0.46017512679100037, 0.5398209691047668, 3.0793430028097646e-07, 1.397771995925723e-07, 2.198320174784385e-07, 3.2413879580417415e-06]\n",
      "logits 3: [7.294384002685547, 7.364057540893555, -7.104798316955566, -7.89853572845459, -7.4433159828186035, -4.699705123901367]\n",
      "probs 3: [0.48258692026138306, 0.5174095034599304, 2.692093516998284e-07, 1.217234739669948e-07, 1.9189957356502418e-07, 2.982694923048257e-06]\n",
      "logits 4: [7.193873405456543, 7.345402717590332, -7.039752006530762, -7.829940319061279, -7.376909255981445, -4.681264400482178]\n",
      "probs 4: [0.4621882438659668, 0.5378079414367676, 3.042523246676865e-07, 1.3805740195493854e-07, 2.17174275007892e-07, 3.2174534680962097e-06]\n",
      "logits 5: [7.291335105895996, 7.363492012023926, -7.10282564163208, -7.896456241607666, -7.4413018226623535, -4.699145317077637]\n",
      "probs 5: [0.48196685314178467, 0.5180295705795288, 2.7021684445571736e-07, 1.2219206269037386e-07, 1.9262563455413328e-07, 2.989631639138679e-06]\n",
      "logits 6: [7.28285026550293, 7.361918926239014, -7.097336769104004, -7.89066743850708, -7.435698986053467, -4.6975884437561035]\n",
      "probs 6: [0.4802413880825043, 0.5197550058364868, 2.7303852334625844e-07, 1.235050177683661e-07, 1.9465915102045983e-07, 3.0089927349763457e-06]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-13.088274955749512, 2.3983683586120605, 7.201931953430176, 7.2594428062438965, 7.211228370666504, -1.0322275161743164]\n",
      "probs 0: [5.011265846732726e-10, 0.0026650845538824797, 0.3249916434288025, 0.3442300856113434, 0.32802698016166687, 8.626256021670997e-05]\n",
      "logits 1: [0.5344668626785278, 4.55538272857666, -1.2637165784835815, -1.64607572555542, -1.416233777999878, -3.5542025566101074]\n",
      "probs 1: [0.01748567633330822, 0.9748640656471252, 0.002895618323236704, 0.001975535647943616, 0.0024860159028321505, 0.0002930867194663733]\n",
      "logits 2: [0.4064137935638428, 5.982634544372559, -2.5499935150146484, -3.089020013809204, -2.7890119552612305, -3.442261219024658]\n",
      "probs 2: [0.003770507639274001, 0.9956842660903931, 0.000196086781215854, 0.00011438056390034035, 0.00015439881826750934, 8.03417424322106e-05]\n",
      "logits 3: [14.499467849731445, 8.090204238891602, -11.190988540649414, -12.171304702758789, -11.589872360229492, -6.058858871459961]\n",
      "probs 3: [0.9983564019203186, 0.0016435305587947369, 6.951238196162279e-12, 2.608052229041702e-12, 4.664757729394564e-12, 1.177382968897689e-09]\n",
      "logits 4: [1.1793986558914185, 6.146997451782227, -3.0699539184570312, -3.638601541519165, -3.3207058906555176, -3.58280611038208]\n",
      "probs 4: [0.006909728515893221, 0.9927999973297119, 9.862583101494238e-05, 5.585090912063606e-05, 7.675217057112604e-05, 5.905572106712498e-05]\n",
      "logits 5: [1.0259205102920532, 6.114540100097656, -2.96688175201416, -3.529668092727661, -3.2153148651123047, -3.554889678955078]\n",
      "probs 5: [0.006126719992607832, 0.9935449361801147, 0.00011302540951874107, 6.438152195187286e-05, 8.816232002573088e-05, 6.277800275711343e-05]\n",
      "logits 6: [14.593137741088867, 8.401905059814453, -11.529316902160645, -12.545636177062988, -11.947364807128906, -6.058104038238525]\n",
      "probs 6: [0.9979568719863892, 0.0020431187003850937, 4.511006585633526e-12, 1.6326444319744726e-12, 2.9697368696124382e-12, 1.0724860999289376e-09]\n",
      "input : [5, 4, 0, 1, 1, 1, 0]\n",
      "preds : [3, 1, 1, 1, 0, 0, 1]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-12.770731925964355, 2.3029632568359375, 7.142064094543457, 7.205504894256592, 7.156447410583496, -1.0998940467834473]\n",
      "probs 0: [7.282539016273404e-10, 0.0025627443101257086, 0.32381731271743774, 0.3450261950492859, 0.32850852608680725, 8.528312901034951e-05]\n",
      "logits 1: [7.324583053588867, 7.369651794433594, -7.124331474304199, -7.919134140014648, -7.463257312774658, -4.705246448516846]\n",
      "probs 1: [0.4887330234050751, 0.5112634897232056, 2.594106831566023e-07, 1.1716810632833585e-07, 1.8483935093627224e-07, 2.914629476435948e-06]\n",
      "logits 2: [7.127796173095703, 7.333109378814697, -6.996962547302246, -7.784812927246094, -7.333223342895508, -4.669143199920654]\n",
      "probs 2: [0.4488494396209717, 0.5511465668678284, 3.294547070709086e-07, 1.4984320273470075e-07, 2.353747703409681e-07, 3.3787421216402436e-06]\n",
      "logits 3: [6.41586446762085, 7.199247360229492, -6.534601211547852, -7.297116279602051, -6.861119747161865, -4.538631439208984]\n",
      "probs 3: [0.31358906626701355, 0.6864039301872253, 7.448093697348668e-07, 3.474473828646296e-07, 5.373282192522311e-07, 5.481302650878206e-06]\n",
      "logits 4: [7.672247886657715, 7.433701992034912, -7.348876953125, -8.155904769897461, -7.692480087280273, -4.7690606117248535]\n",
      "probs 4: [0.5593538284301758, 0.4406435787677765, 1.6753092779708822e-07, 7.474931607021063e-08, 1.1881466122076745e-07, 2.210521643064567e-06]\n",
      "logits 5: [7.701807022094727, 7.439116477966309, -7.36793851852417, -8.176002502441406, -7.711936950683594, -4.7744879722595215]\n",
      "probs 5: [0.5652961134910583, 0.4347013235092163, 1.6127552271427703e-07, 7.188378958744579e-08, 1.1433312607778134e-07, 2.1571966044575674e-06]\n",
      "logits 6: [6.340918064117432, 7.1850104331970215, -6.485790252685547, -7.245622158050537, -6.811275005340576, -4.524901390075684]\n",
      "probs 6: [0.3006713390350342, 0.6993211507797241, 8.082079716587032e-07, 3.780354518312379e-07, 5.836697027916671e-07, 5.742840585298836e-06]\n"
     ]
    }
   ],
   "source": [
    "base_model = base_model.to(device)\n",
    "test_model(model, batch_size, seq_len, vocab_size)\n",
    "test_model(base_model, batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2733b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0459  avg_reward=0.874 KL=0.303: 100%|██████████| 1000/1000 [01:01<00:00, 16.27it/s]\n"
     ]
    }
   ],
   "source": [
    "model = rl_model(base_model, rl_batch_size=rl_batch_size, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948afbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-4): 5 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [-4.384078025817871, 6.779410362243652, -2.4497241973876953, -3.0086758136749268, -2.4025156497955322, -4.811733245849609]\n",
      "probs 1: [1.4178710443957243e-05, 0.9997194409370422, 9.811059862840921e-05, 5.6100459914887324e-05, 0.00010285335156368092, 9.245032742910553e-06]\n",
      "logits 2: [-3.855494260787964, 6.995876312255859, -2.9078097343444824, -3.5130255222320557, -2.866472005844116, -4.843070983886719]\n",
      "probs 2: [1.937500201165676e-05, 0.999843955039978, 4.9982252676272765e-05, 2.7288162527838722e-05, 5.2091720135649666e-05, 7.216768153739395e-06]\n",
      "logits 3: [8.795400619506836, 1.8230936527252197, -5.532688617706299, -6.684474945068359, -5.6692376136779785, 0.2598237991333008]\n",
      "probs 3: [0.9988662004470825, 0.0009364245343022048, 5.982702759865788e-07, 1.8909619825535628e-07, 5.219092145125614e-07, 0.0001961342350114137]\n",
      "logits 4: [-3.605093240737915, 7.085966110229492, -3.1147820949554443, -3.741239309310913, -3.076270580291748, -4.850874900817871]\n",
      "probs 4: [2.2744574380340055e-05, 0.9998750686645508, 3.71378700947389e-05, 1.9849523596349172e-05, 3.859599746647291e-05, 6.54397399557638e-06]\n",
      "logits 5: [-3.2159905433654785, 7.211433410644531, -3.4247031211853027, -4.0833821296691895, -3.3906357288360596, -4.854791641235352]\n",
      "probs 5: [2.960639540106058e-05, 0.9999033212661743, 2.4029372070799582e-05, 1.2436041288310662e-05, 2.4862110876711085e-05, 5.7499369177094195e-06]\n",
      "logits 6: [8.744879722595215, 1.1408237218856812, -4.956073760986328, -6.067610740661621, -5.094448566436768, 0.6368124485015869]\n",
      "probs 6: [0.9991987347602844, 0.0004980263765901327, 1.1204780321349972e-06, 3.6869647601633915e-07, 9.75680791270861e-07, 0.00030085889738984406]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [4, 1, 0, 1, 0, 0, 1]\n",
      "reward: 0.42857142857142855\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [4.674300193786621, 6.795696258544922, -7.32538366317749, -8.477158546447754, -7.39211893081665, -3.2609283924102783]\n",
      "probs 1: [0.10703030228614807, 0.8929299116134644, 6.578245574928587e-07, 2.079221701478673e-07, 6.153578624434886e-07, 3.8307243812596425e-05]\n",
      "logits 2: [8.767640113830566, 2.241039276123047, -5.854397773742676, -7.027003765106201, -5.989088535308838, 0.018777191638946533]\n",
      "probs 2: [0.9983789920806885, 0.0014616006519645452, 4.4568196244654246e-07, 1.37965017188435e-07, 3.895196698522341e-07, 0.00015838439867366105]\n",
      "logits 3: [-3.270353078842163, 7.194924354553223, -3.3822247982025146, -4.036457538604736, -3.3475325107574463, -4.85482120513916]\n",
      "probs 3: [2.850653800123837e-05, 0.9999005794525146, 2.548937663959805e-05, 1.3250413758214563e-05, 2.638919249875471e-05, 5.845462055731332e-06]\n",
      "logits 4: [8.734368324279785, 1.0790910720825195, -4.900712013244629, -6.008218288421631, -5.039177417755127, 0.6698998212814331]\n",
      "probs 4: [0.9992098808288574, 0.0004731644003186375, 1.196786229229474e-06, 3.953965972414153e-07, 1.042033318299218e-06, 0.00031426979694515467]\n",
      "logits 5: [8.715490341186523, 0.9804403781890869, -4.811125755310059, -5.912055969238281, -4.949709892272949, 0.7224161624908447]\n",
      "probs 5: [0.9992226362228394, 0.00043689057929441333, 1.3339130191525328e-06, 4.436082576830813e-07, 1.161291379503382e-06, 0.00033753138268366456]\n",
      "logits 6: [-4.095829010009766, 6.902059555053711, -2.7032370567321777, -3.2876670360565186, -2.6592135429382324, -4.831425666809082]\n",
      "probs 6: [1.6733654774725437e-05, 0.9998000264167786, 6.735744682373479e-05, 3.7546633393503726e-05, 7.038899639155716e-05, 8.01909300207626e-06]\n",
      "input : [5, 4, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 1, 0, 0, 1]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [4.755037307739258, 6.760960578918457, -7.340746879577637, -8.495916366577148, -7.408624172210693, -3.2273876667022705]\n",
      "probs 1: [0.11857745051383972, 0.8813806176185608, 6.620179533456394e-07, 2.085383954408826e-07, 6.185733809616067e-07, 4.0483599150320515e-05]\n",
      "logits 2: [4.610212326049805, 6.8226776123046875, -7.312711715698242, -8.461758613586426, -7.378542900085449, -3.2872180938720703]\n",
      "probs 2: [0.09863290935754776, 0.9013289213180542, 6.545785140588123e-07, 2.0746125528603443e-07, 6.128746008471353e-07, 3.6661596823250875e-05]\n",
      "logits 3: [2.75398325920105, 7.40516471862793, -6.785418510437012, -7.8447113037109375, -6.825786590576172, -3.9361751079559326]\n",
      "probs 3: [0.00945984199643135, 0.9905267953872681, 6.807289878452139e-07, 2.3600935605827544e-07, 6.53796575988963e-07, 1.175939087261213e-05]\n",
      "logits 4: [6.080227851867676, 6.053250312805176, -7.4821248054504395, -8.685565948486328, -7.569233417510986, -2.5990960597991943]\n",
      "probs 4: [0.5066995620727539, 0.4932127892971039, 6.526726679112471e-07, 1.9590601141317165e-07, 5.982250286251656e-07, 8.617234561825171e-05]\n",
      "logits 5: [6.092293739318848, 6.045412063598633, -7.482288360595703, -8.6860933303833, -7.569577693939209, -2.5925872325897217]\n",
      "probs 5: [0.5116732716560364, 0.48823878169059753, 6.510684329441574e-07, 1.9535332285158802e-07, 5.966471690044273e-07, 8.653598342789337e-05]\n",
      "logits 6: [-1.3984289169311523, 7.593721389770508, -4.708263874053955, -5.5064191818237305, -4.6956915855407715, -4.757884979248047]\n",
      "probs 6: [0.00012436496035661548, 0.9998601675033569, 4.542083843261935e-06, 2.0446573216759134e-06, 4.599544354277896e-06, 4.322199401940452e-06]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [4, 1, 0, 1, 0, 0, 1]\n",
      "reward: 0.42857142857142855\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [4.674300193786621, 6.795696258544922, -7.32538366317749, -8.477158546447754, -7.39211893081665, -3.2609283924102783]\n",
      "probs 1: [0.10703030228614807, 0.8929299116134644, 6.578245574928587e-07, 2.079221701478673e-07, 6.153578624434886e-07, 3.8307243812596425e-05]\n",
      "logits 2: [8.767640113830566, 2.241039276123047, -5.854397773742676, -7.027003765106201, -5.989088535308838, 0.018777191638946533]\n",
      "probs 2: [0.9983789920806885, 0.0014616006519645452, 4.4568196244654246e-07, 1.37965017188435e-07, 3.895196698522341e-07, 0.00015838439867366105]\n",
      "logits 3: [-3.270353078842163, 7.194924354553223, -3.3822247982025146, -4.036457538604736, -3.3475325107574463, -4.85482120513916]\n",
      "probs 3: [2.850653800123837e-05, 0.9999005794525146, 2.548937663959805e-05, 1.3250413758214563e-05, 2.638919249875471e-05, 5.845462055731332e-06]\n",
      "logits 4: [8.734368324279785, 1.0790910720825195, -4.900712013244629, -6.008218288421631, -5.039177417755127, 0.6698998212814331]\n",
      "probs 4: [0.9992098808288574, 0.0004731644003186375, 1.196786229229474e-06, 3.953965972414153e-07, 1.042033318299218e-06, 0.00031426979694515467]\n",
      "logits 5: [8.715490341186523, 0.9804403781890869, -4.811125755310059, -5.912055969238281, -4.949709892272949, 0.7224161624908447]\n",
      "probs 5: [0.9992226362228394, 0.00043689057929441333, 1.3339130191525328e-06, 4.436082576830813e-07, 1.161291379503382e-06, 0.00033753138268366456]\n",
      "logits 6: [-4.095829010009766, 6.902059555053711, -2.7032370567321777, -3.2876670360565186, -2.6592135429382324, -4.831425666809082]\n",
      "probs 6: [1.6733654774725437e-05, 0.9998000264167786, 6.735744682373479e-05, 3.7546633393503726e-05, 7.038899639155716e-05, 8.01909300207626e-06]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [-4.384078025817871, 6.779410362243652, -2.4497241973876953, -3.0086758136749268, -2.4025156497955322, -4.811733245849609]\n",
      "probs 1: [1.4178710443957243e-05, 0.9997194409370422, 9.811059862840921e-05, 5.6100459914887324e-05, 0.00010285335156368092, 9.245032742910553e-06]\n",
      "logits 2: [-3.855494260787964, 6.995876312255859, -2.9078097343444824, -3.5130255222320557, -2.866472005844116, -4.843070983886719]\n",
      "probs 2: [1.937500201165676e-05, 0.999843955039978, 4.9982252676272765e-05, 2.7288162527838722e-05, 5.2091720135649666e-05, 7.216768153739395e-06]\n",
      "logits 3: [8.795400619506836, 1.8230936527252197, -5.532688617706299, -6.684474945068359, -5.6692376136779785, 0.2598237991333008]\n",
      "probs 3: [0.9988662004470825, 0.0009364245343022048, 5.982702759865788e-07, 1.8909619825535628e-07, 5.219092145125614e-07, 0.0001961342350114137]\n",
      "logits 4: [-3.605093240737915, 7.085966110229492, -3.1147820949554443, -3.741239309310913, -3.076270580291748, -4.850874900817871]\n",
      "probs 4: [2.2744574380340055e-05, 0.9998750686645508, 3.71378700947389e-05, 1.9849523596349172e-05, 3.859599746647291e-05, 6.54397399557638e-06]\n",
      "logits 5: [-3.2159905433654785, 7.211433410644531, -3.4247031211853027, -4.0833821296691895, -3.3906357288360596, -4.854791641235352]\n",
      "probs 5: [2.960639540106058e-05, 0.9999033212661743, 2.4029372070799582e-05, 1.2436041288310662e-05, 2.4862110876711085e-05, 5.7499369177094195e-06]\n",
      "logits 6: [8.744879722595215, 1.1408237218856812, -4.956073760986328, -6.067610740661621, -5.094448566436768, 0.6368124485015869]\n",
      "probs 6: [0.9991987347602844, 0.0004980263765901327, 1.1204780321349972e-06, 3.6869647601633915e-07, 9.75680791270861e-07, 0.00030085889738984406]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.5714285714285714\n",
      "logits 0: [-6.792204856872559, -0.9793281555175781, 5.091799259185791, 5.110385894775391, 5.141311168670654, -0.840417206287384]\n",
      "probs 0: [2.24424456973793e-06, 0.0007508795242756605, 0.3252575397491455, 0.33135953545570374, 0.34176698327064514, 0.0008627767092548311]\n",
      "logits 1: [-4.384078025817871, 6.779410362243652, -2.4497241973876953, -3.0086758136749268, -2.4025156497955322, -4.811733245849609]\n",
      "probs 1: [1.4178710443957243e-05, 0.9997194409370422, 9.811059862840921e-05, 5.6100459914887324e-05, 0.00010285335156368092, 9.245032742910553e-06]\n",
      "logits 2: [-3.855494260787964, 6.995876312255859, -2.9078097343444824, -3.5130255222320557, -2.866472005844116, -4.843070983886719]\n",
      "probs 2: [1.937500201165676e-05, 0.999843955039978, 4.9982252676272765e-05, 2.7288162527838722e-05, 5.2091720135649666e-05, 7.216768153739395e-06]\n",
      "logits 3: [8.795400619506836, 1.8230936527252197, -5.532688617706299, -6.684474945068359, -5.6692376136779785, 0.2598237991333008]\n",
      "probs 3: [0.9988662004470825, 0.0009364245343022048, 5.982702759865788e-07, 1.8909619825535628e-07, 5.219092145125614e-07, 0.0001961342350114137]\n",
      "logits 4: [-3.605093240737915, 7.085966110229492, -3.1147820949554443, -3.741239309310913, -3.076270580291748, -4.850874900817871]\n",
      "probs 4: [2.2744574380340055e-05, 0.9998750686645508, 3.71378700947389e-05, 1.9849523596349172e-05, 3.859599746647291e-05, 6.54397399557638e-06]\n",
      "logits 5: [-3.2159905433654785, 7.211433410644531, -3.4247031211853027, -4.0833821296691895, -3.3906357288360596, -4.854791641235352]\n",
      "probs 5: [2.960639540106058e-05, 0.9999033212661743, 2.4029372070799582e-05, 1.2436041288310662e-05, 2.4862110876711085e-05, 5.7499369177094195e-06]\n",
      "logits 6: [8.744879722595215, 1.1408237218856812, -4.956073760986328, -6.067610740661621, -5.094448566436768, 0.6368124485015869]\n",
      "probs 6: [0.9991987347602844, 0.0004980263765901327, 1.1204780321349972e-06, 3.6869647601633915e-07, 9.75680791270861e-07, 0.00030085889738984406]\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e82db5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model param count: 220\n",
      "Model count by layer:\n",
      "('pos_emb', Parameter containing:\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0', requires_grad=True))\n",
      "('embedding.weight', Parameter containing:\n",
      "tensor([[ 0.6441,  0.9567, -0.7844],\n",
      "        [ 0.4242,  0.6012,  0.6982],\n",
      "        [-0.3143, -0.2192, -0.1752],\n",
      "        [-0.1912, -2.8662,  1.0095],\n",
      "        [ 0.5639,  0.9740,  0.8723],\n",
      "        [-0.2110, -0.3603, -1.0006]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.2194,  0.1722, -0.6215],\n",
      "        [ 0.3079, -0.6127,  0.2562],\n",
      "        [-0.1280, -0.0357, -0.5009],\n",
      "        [ 0.4075,  0.0641, -0.4380],\n",
      "        [ 0.6149, -0.3556,  0.4145],\n",
      "        [ 0.3789, -0.5826, -0.4429],\n",
      "        [ 0.1451, -0.5592, -0.2609],\n",
      "        [ 0.6689, -0.0197, -0.3486],\n",
      "        [-0.0600, -0.5176, -0.6194]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.5406, -0.4417,  0.1390],\n",
      "        [ 0.4979, -0.3170,  0.2972],\n",
      "        [ 0.1835, -0.0930,  0.0149]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0162, -0.1836,  0.5558],\n",
      "        [ 0.5583,  0.2959,  0.0932]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.bias', Parameter containing:\n",
      "tensor([-0.4459, -0.2944], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.weight', Parameter containing:\n",
      "tensor([[-0.1045,  0.2594],\n",
      "        [-0.4442, -0.4476],\n",
      "        [ 0.5426, -0.1670]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.bias', Parameter containing:\n",
      "tensor([-0.6499,  0.0993, -0.3733], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.2194,  0.1722, -0.6215],\n",
      "        [ 0.3079, -0.6127,  0.2562],\n",
      "        [-0.1280, -0.0357, -0.5009],\n",
      "        [ 0.4075,  0.0641, -0.4380],\n",
      "        [ 0.6149, -0.3556,  0.4145],\n",
      "        [ 0.3789, -0.5826, -0.4429],\n",
      "        [ 0.1451, -0.5592, -0.2609],\n",
      "        [ 0.6689, -0.0197, -0.3486],\n",
      "        [-0.0600, -0.5176, -0.6194]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.5406, -0.4417,  0.1390],\n",
      "        [ 0.4979, -0.3170,  0.2972],\n",
      "        [ 0.1835, -0.0930,  0.0149]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0162, -0.1836,  0.5558],\n",
      "        [ 0.5583,  0.2959,  0.0932]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.bias', Parameter containing:\n",
      "tensor([-0.4459, -0.2944], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.weight', Parameter containing:\n",
      "tensor([[-0.1045,  0.2594],\n",
      "        [-0.4442, -0.4476],\n",
      "        [ 0.5426, -0.1670]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.bias', Parameter containing:\n",
      "tensor([-0.6499,  0.0993, -0.3733], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('head.weight', Parameter containing:\n",
      "tensor([[-0.5386,  0.5317,  0.3039],\n",
      "        [ 0.5283,  0.3198, -0.2793],\n",
      "        [-0.0364,  0.4432,  0.4009],\n",
      "        [ 0.2616,  0.0984, -0.2658],\n",
      "        [-0.2225, -0.2745, -0.2570],\n",
      "        [ 0.5558,  0.4485,  0.4534]], device='cuda:0', requires_grad=True))\n",
      "('head.bias', Parameter containing:\n",
      "tensor([-0.0171, -0.1038, -0.2198,  0.5529, -0.1742, -0.4430], device='cuda:0',\n",
      "       requires_grad=True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.3722919821739197: 100%|██████████| 500/500 [00:13<00:00, 38.08it/s] \n",
      "loss=-0.0031  avg_reward=0.533 KL=0.018: 100%|██████████| 1000/1000 [00:27<00:00, 36.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 4, 1, 1, 0, 1, 0]\n",
      "preds : [4, 1, 1, 1, 1, 0, 1]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [5.30952787399292, 5.464614391326904, -5.16754674911499, -4.583096504211426, -5.207266807556152, -2.1194863319396973]\n",
      "probs 1: [0.46115708351135254, 0.538520336151123, 1.2993113159609493e-05, 2.3309714379138313e-05, 1.2487146705097985e-05, 0.00027382245752960443]\n",
      "logits 2: [5.2901482582092285, 5.475961208343506, -5.165719509124756, -4.581154823303223, -5.2053985595703125, -2.1237707138061523]\n",
      "probs 2: [0.45353370904922485, 0.5461438894271851, 1.3052203939878382e-05, 2.341840445296839e-05, 1.2544439414341468e-05, 0.0002733917790465057]\n",
      "logits 3: [5.3731689453125, 5.426865100860596, -5.173288345336914, -4.589237213134766, -5.213142395019531, -2.1053452491760254]\n",
      "probs 3: [0.486422061920166, 0.5132550001144409, 1.2786310435330961e-05, 2.2929547412786633e-05, 1.228674500453053e-05, 0.00027487537590786815]\n",
      "logits 4: [5.372634410858154, 5.427184581756592, -5.17324161529541, -4.589187145233154, -5.213094711303711, -2.105464458465576]\n",
      "probs 4: [0.4862087666988373, 0.5134682655334473, 1.2788134881702717e-05, 2.2932881620363332e-05, 1.2288497600820847e-05, 0.0002748689439613372]\n",
      "logits 5: [5.412921905517578, 5.402900695800781, -5.176671981811523, -4.592887878417969, -5.21660852432251, -2.0964560508728027]\n",
      "probs 5: [0.5023431181907654, 0.49733418226242065, 1.2647312360059004e-05, 2.2674226784147322e-05, 1.215218253491912e-05, 0.00027524473262019455]\n",
      "logits 6: [5.386240482330322, 5.419017314910889, -5.174417495727539, -4.590453147888184, -5.21429967880249, -2.1024270057678223]\n",
      "probs 6: [0.49164777994155884, 0.5080294013023376, 1.2741435966745485e-05, 2.2847110813017935e-05, 1.2243284800206311e-05, 0.0002750217681750655]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [-1.35435152053833, 6.6736273765563965, -3.1170990467071533, -2.6178929805755615, -3.133822441101074, -3.1962249279022217]\n",
      "probs 1: [0.0003260173834860325, 0.9994192123413086, 5.593570676865056e-05, 9.214924648404121e-05, 5.50080876564607e-05, 5.168034476810135e-05]\n",
      "logits 2: [-0.5062980651855469, 6.770416259765625, -3.5104339122772217, -2.988774538040161, -3.530900001525879, -3.0961010456085205]\n",
      "probs 2: [0.0006908533978275955, 0.9991317391395569, 3.425359682296403e-05, 5.771120413555764e-05, 3.3559688745299354e-05, 5.183807297726162e-05]\n",
      "logits 3: [8.11927318572998, -0.6076599359512329, -3.093989133834839, -2.7311456203460693, -3.125309944152832, -0.8465196490287781]\n",
      "probs 3: [0.999664306640625, 0.0001621045230422169, 1.3489508091879543e-05, 1.9389966837479733e-05, 1.3073557056486607e-05, 0.0001276614930247888]\n",
      "logits 4: [-1.504389762878418, 6.648680686950684, -3.043377637863159, -2.548506498336792, -3.0594143867492676, -3.2127866744995117]\n",
      "probs 4: [0.0002876879589166492, 0.9994364380836487, 6.173730071168393e-05, 0.00010126687993761152, 6.07551155553665e-05, 5.211638563196175e-05]\n",
      "logits 5: [0.30297067761421204, 6.7961273193359375, -3.8505749702453613, -3.310574769973755, -3.8743948936462402, -2.9907429218292236]\n",
      "probs 5: [0.0015112580731511116, 0.9983450174331665, 2.373978895775508e-05, 4.0737631934462115e-05, 2.318096812814474e-05, 5.609149593510665e-05]\n",
      "logits 6: [8.138143539428711, -0.5588363409042358, -3.127392292022705, -2.7618885040283203, -3.1589484214782715, -0.8511630296707153]\n",
      "probs 6: [0.9996646642684937, 0.0001670336932875216, 1.2802491255570203e-05, 1.8451451978762634e-05, 1.2404791050357744e-05, 0.0001246947649633512]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [4, 0, 0, 1, 0, 0, 1]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [8.360946655273438, 0.30283451080322266, -3.672431707382202, -3.262310028076172, -3.707691192626953, -0.9479787349700928]\n",
      "probs 1: [0.9995724558830261, 0.00031638843938708305, 5.939971288171364e-06, 8.951546078606043e-06, 5.734182195737958e-06, 9.057310671778396e-05]\n",
      "logits 2: [8.158817291259766, 2.2574708461761475, -4.6233015060424805, -4.126962184906006, -4.664102554321289, -1.2630219459533691]\n",
      "probs 2: [0.9971810579299927, 0.00272804731503129, 2.8026597647112794e-06, 4.603918114298722e-06, 2.6906097900791792e-06, 8.070890180533752e-05]\n",
      "logits 3: [-1.5748260021209717, 6.6361260414123535, -3.008323907852173, -2.51552677154541, -3.0240349769592285, -3.220438003540039]\n",
      "probs 3: [0.00027151036192663014, 0.9994415640830994, 6.474793917732313e-05, 0.00010598511289572343, 6.373864016495645e-05, 5.237285222392529e-05]\n",
      "logits 4: [8.378524780273438, 0.4440004825592041, -3.7540879249572754, -3.3370578289031982, -3.7898778915405273, -0.9663918018341064]\n",
      "probs 4: [0.9995359182357788, 0.00035799603210762143, 5.378632522479165e-06, 8.161789992300328e-06, 5.1895326578232925e-06, 8.736809104448184e-05]\n",
      "logits 5: [8.396707534790039, 0.683924674987793, -3.888153314590454, -3.4596285820007324, -3.9247970581054688, -0.9992637634277344]\n",
      "probs 5: [0.9994539618492126, 0.0004468314873520285, 4.618656021193601e-06, 7.0895916906010825e-06, 4.452473604033003e-06, 8.301265916088596e-05]\n",
      "logits 6: [-1.3838081359863281, 6.668920516967773, -3.102726697921753, -2.604362726211548, -3.1193161010742188, -3.1995043754577637]\n",
      "probs 6: [0.00031804884201847017, 0.9994232654571533, 5.7013392506632954e-05, 9.384558507008478e-05, 5.6075390602927655e-05, 5.175433761905879e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [-1.35435152053833, 6.6736273765563965, -3.1170990467071533, -2.6178929805755615, -3.133822441101074, -3.1962249279022217]\n",
      "probs 1: [0.0003260173834860325, 0.9994192123413086, 5.593570676865056e-05, 9.214924648404121e-05, 5.50080876564607e-05, 5.168034476810135e-05]\n",
      "logits 2: [-0.5062980651855469, 6.770416259765625, -3.5104339122772217, -2.988774538040161, -3.530900001525879, -3.0961010456085205]\n",
      "probs 2: [0.0006908533978275955, 0.9991317391395569, 3.425359682296403e-05, 5.771120413555764e-05, 3.3559688745299354e-05, 5.183807297726162e-05]\n",
      "logits 3: [8.11927318572998, -0.6076599359512329, -3.093989133834839, -2.7311456203460693, -3.125309944152832, -0.8465196490287781]\n",
      "probs 3: [0.999664306640625, 0.0001621045230422169, 1.3489508091879543e-05, 1.9389966837479733e-05, 1.3073557056486607e-05, 0.0001276614930247888]\n",
      "logits 4: [-1.504389762878418, 6.648680686950684, -3.043377637863159, -2.548506498336792, -3.0594143867492676, -3.2127866744995117]\n",
      "probs 4: [0.0002876879589166492, 0.9994364380836487, 6.173730071168393e-05, 0.00010126687993761152, 6.07551155553665e-05, 5.211638563196175e-05]\n",
      "logits 5: [0.30297067761421204, 6.7961273193359375, -3.8505749702453613, -3.310574769973755, -3.8743948936462402, -2.9907429218292236]\n",
      "probs 5: [0.0015112580731511116, 0.9983450174331665, 2.373978895775508e-05, 4.0737631934462115e-05, 2.318096812814474e-05, 5.609149593510665e-05]\n",
      "logits 6: [8.138143539428711, -0.5588363409042358, -3.127392292022705, -2.7618885040283203, -3.1589484214782715, -0.8511630296707153]\n",
      "probs 6: [0.9996646642684937, 0.0001670336932875216, 1.2802491255570203e-05, 1.8451451978762634e-05, 1.2404791050357744e-05, 0.0001246947649633512]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [-1.35435152053833, 6.6736273765563965, -3.1170990467071533, -2.6178929805755615, -3.133822441101074, -3.1962249279022217]\n",
      "probs 1: [0.0003260173834860325, 0.9994192123413086, 5.593570676865056e-05, 9.214924648404121e-05, 5.50080876564607e-05, 5.168034476810135e-05]\n",
      "logits 2: [-0.5062980651855469, 6.770416259765625, -3.5104339122772217, -2.988774538040161, -3.530900001525879, -3.0961010456085205]\n",
      "probs 2: [0.0006908533978275955, 0.9991317391395569, 3.425359682296403e-05, 5.771120413555764e-05, 3.3559688745299354e-05, 5.183807297726162e-05]\n",
      "logits 3: [8.11927318572998, -0.6076599359512329, -3.093989133834839, -2.7311456203460693, -3.125309944152832, -0.8465196490287781]\n",
      "probs 3: [0.999664306640625, 0.0001621045230422169, 1.3489508091879543e-05, 1.9389966837479733e-05, 1.3073557056486607e-05, 0.0001276614930247888]\n",
      "logits 4: [-1.504389762878418, 6.648680686950684, -3.043377637863159, -2.548506498336792, -3.0594143867492676, -3.2127866744995117]\n",
      "probs 4: [0.0002876879589166492, 0.9994364380836487, 6.173730071168393e-05, 0.00010126687993761152, 6.07551155553665e-05, 5.211638563196175e-05]\n",
      "logits 5: [0.30297067761421204, 6.7961273193359375, -3.8505749702453613, -3.310574769973755, -3.8743948936462402, -2.9907429218292236]\n",
      "probs 5: [0.0015112580731511116, 0.9983450174331665, 2.373978895775508e-05, 4.0737631934462115e-05, 2.318096812814474e-05, 5.609149593510665e-05]\n",
      "logits 6: [8.138143539428711, -0.5588363409042358, -3.127392292022705, -2.7618885040283203, -3.1589484214782715, -0.8511630296707153]\n",
      "probs 6: [0.9996646642684937, 0.0001670336932875216, 1.2802491255570203e-05, 1.8451451978762634e-05, 1.2404791050357744e-05, 0.0001246947649633512]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [4, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-4.60508394241333, -2.3911492824554443, 2.9826507568359375, 2.993257999420166, 3.008551597595215, -2.30002498626709]\n",
      "probs 0: [0.00016626407159492373, 0.0015215910971164703, 0.3281782269477844, 0.3316778242588043, 0.3367893397808075, 0.001666759024374187]\n",
      "logits 1: [-1.35435152053833, 6.6736273765563965, -3.1170990467071533, -2.6178929805755615, -3.133822441101074, -3.1962249279022217]\n",
      "probs 1: [0.0003260173834860325, 0.9994192123413086, 5.593570676865056e-05, 9.214924648404121e-05, 5.50080876564607e-05, 5.168034476810135e-05]\n",
      "logits 2: [-0.5062980651855469, 6.770416259765625, -3.5104339122772217, -2.988774538040161, -3.530900001525879, -3.0961010456085205]\n",
      "probs 2: [0.0006908533978275955, 0.9991317391395569, 3.425359682296403e-05, 5.771120413555764e-05, 3.3559688745299354e-05, 5.183807297726162e-05]\n",
      "logits 3: [8.11927318572998, -0.6076599359512329, -3.093989133834839, -2.7311456203460693, -3.125309944152832, -0.8465196490287781]\n",
      "probs 3: [0.999664306640625, 0.0001621045230422169, 1.3489508091879543e-05, 1.9389966837479733e-05, 1.3073557056486607e-05, 0.0001276614930247888]\n",
      "logits 4: [-1.504389762878418, 6.648680686950684, -3.043377637863159, -2.548506498336792, -3.0594143867492676, -3.2127866744995117]\n",
      "probs 4: [0.0002876879589166492, 0.9994364380836487, 6.173730071168393e-05, 0.00010126687993761152, 6.07551155553665e-05, 5.211638563196175e-05]\n",
      "logits 5: [0.30297067761421204, 6.7961273193359375, -3.8505749702453613, -3.310574769973755, -3.8743948936462402, -2.9907429218292236]\n",
      "probs 5: [0.0015112580731511116, 0.9983450174331665, 2.373978895775508e-05, 4.0737631934462115e-05, 2.318096812814474e-05, 5.609149593510665e-05]\n",
      "logits 6: [8.138143539428711, -0.5588363409042358, -3.127392292022705, -2.7618885040283203, -3.1589484214782715, -0.8511630296707153]\n",
      "probs 6: [0.9996646642684937, 0.0001670336932875216, 1.2802491255570203e-05, 1.8451451978762634e-05, 1.2404791050357744e-05, 0.0001246947649633512]\n",
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [-1.194352626800537, 6.75994348526001, -3.2253427505493164, -2.862521171569824, -3.3425023555755615, -3.1332345008850098]\n",
      "probs 1: [0.00035095555358566344, 0.9994452595710754, 4.6047294745221734e-05, 6.618743645958602e-05, 4.0956478187581524e-05, 5.049012179370038e-05]\n",
      "logits 2: [-0.16354942321777344, 6.8539509773254395, -3.691258192062378, -3.312537431716919, -3.8200817108154297, -3.0034537315368652]\n",
      "probs 2: [0.0008951348718255758, 0.998964786529541, 2.6292031179764308e-05, 3.8397258322220296e-05, 2.3114096620702185e-05, 5.230385431786999e-05]\n",
      "logits 3: [8.106917381286621, -0.5523026585578918, -3.120180368423462, -2.832517147064209, -3.2076423168182373, -0.8180078268051147]\n",
      "probs 3: [0.9996503591537476, 0.00017345897504128516, 1.3303982086654287e-05, 1.7738309907144867e-05, 1.2189817425678484e-05, 0.00013298496196512133]\n",
      "logits 4: [-1.610490322113037, 6.690598011016846, -3.0206735134124756, -2.665111541748047, -3.1326045989990234, -3.1812257766723633]\n",
      "probs 4: [0.00024812217452563345, 0.9994992017745972, 6.0566286265384406e-05, 8.642703323857859e-05, 5.4152682423591614e-05, 5.158265048521571e-05]\n",
      "logits 5: [0.43944263458251953, 6.8601508140563965, -3.9380407333374023, -3.551326274871826, -4.072880744934082, -2.920694351196289]\n",
      "probs 5: [0.0016246562590822577, 0.9982506632804871, 2.0400688299559988e-05, 3.0032575523364358e-05, 1.782725848897826e-05, 5.642510222969577e-05]\n",
      "logits 6: [8.36470890045166, 0.5684826970100403, -3.816131591796875, -3.495096206665039, -3.9246561527252197, -0.9393982887268066]\n",
      "probs 6: [0.9994811415672302, 0.000411070795962587, 5.1251049626444e-06, 7.065236331982305e-06, 4.598024588631233e-06, 9.100222086999565e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [-1.194352626800537, 6.75994348526001, -3.2253427505493164, -2.862521171569824, -3.3425023555755615, -3.1332345008850098]\n",
      "probs 1: [0.00035095555358566344, 0.9994452595710754, 4.6047294745221734e-05, 6.618743645958602e-05, 4.0956478187581524e-05, 5.049012179370038e-05]\n",
      "logits 2: [-0.16354942321777344, 6.8539509773254395, -3.691258192062378, -3.312537431716919, -3.8200817108154297, -3.0034537315368652]\n",
      "probs 2: [0.0008951348718255758, 0.998964786529541, 2.6292031179764308e-05, 3.8397258322220296e-05, 2.3114096620702185e-05, 5.230385431786999e-05]\n",
      "logits 3: [8.106917381286621, -0.5523026585578918, -3.120180368423462, -2.832517147064209, -3.2076423168182373, -0.8180078268051147]\n",
      "probs 3: [0.9996503591537476, 0.00017345897504128516, 1.3303982086654287e-05, 1.7738309907144867e-05, 1.2189817425678484e-05, 0.00013298496196512133]\n",
      "logits 4: [-1.610490322113037, 6.690598011016846, -3.0206735134124756, -2.665111541748047, -3.1326045989990234, -3.1812257766723633]\n",
      "probs 4: [0.00024812217452563345, 0.9994992017745972, 6.0566286265384406e-05, 8.642703323857859e-05, 5.4152682423591614e-05, 5.158265048521571e-05]\n",
      "logits 5: [0.43944263458251953, 6.8601508140563965, -3.9380407333374023, -3.551326274871826, -4.072880744934082, -2.920694351196289]\n",
      "probs 5: [0.0016246562590822577, 0.9982506632804871, 2.0400688299559988e-05, 3.0032575523364358e-05, 1.782725848897826e-05, 5.642510222969577e-05]\n",
      "logits 6: [8.36470890045166, 0.5684826970100403, -3.816131591796875, -3.495096206665039, -3.9246561527252197, -0.9393982887268066]\n",
      "probs 6: [0.9994811415672302, 0.000411070795962587, 5.1251049626444e-06, 7.065236331982305e-06, 4.598024588631233e-06, 9.100222086999565e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [3, 1, 1, 0, 1, 1, 0]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [-1.194352626800537, 6.75994348526001, -3.2253427505493164, -2.862521171569824, -3.3425023555755615, -3.1332345008850098]\n",
      "probs 1: [0.00035095555358566344, 0.9994452595710754, 4.6047294745221734e-05, 6.618743645958602e-05, 4.0956478187581524e-05, 5.049012179370038e-05]\n",
      "logits 2: [-0.16354942321777344, 6.8539509773254395, -3.691258192062378, -3.312537431716919, -3.8200817108154297, -3.0034537315368652]\n",
      "probs 2: [0.0008951348718255758, 0.998964786529541, 2.6292031179764308e-05, 3.8397258322220296e-05, 2.3114096620702185e-05, 5.230385431786999e-05]\n",
      "logits 3: [8.106917381286621, -0.5523026585578918, -3.120180368423462, -2.832517147064209, -3.2076423168182373, -0.8180078268051147]\n",
      "probs 3: [0.9996503591537476, 0.00017345897504128516, 1.3303982086654287e-05, 1.7738309907144867e-05, 1.2189817425678484e-05, 0.00013298496196512133]\n",
      "logits 4: [-1.610490322113037, 6.690598011016846, -3.0206735134124756, -2.665111541748047, -3.1326045989990234, -3.1812257766723633]\n",
      "probs 4: [0.00024812217452563345, 0.9994992017745972, 6.0566286265384406e-05, 8.642703323857859e-05, 5.4152682423591614e-05, 5.158265048521571e-05]\n",
      "logits 5: [0.43944263458251953, 6.8601508140563965, -3.9380407333374023, -3.551326274871826, -4.072880744934082, -2.920694351196289]\n",
      "probs 5: [0.0016246562590822577, 0.9982506632804871, 2.0400688299559988e-05, 3.0032575523364358e-05, 1.782725848897826e-05, 5.642510222969577e-05]\n",
      "logits 6: [8.36470890045166, 0.5684826970100403, -3.816131591796875, -3.495096206665039, -3.9246561527252197, -0.9393982887268066]\n",
      "probs 6: [0.9994811415672302, 0.000411070795962587, 5.1251049626444e-06, 7.065236331982305e-06, 4.598024588631233e-06, 9.100222086999565e-05]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [3, 0, 0, 1, 0, 0, 1]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [8.349299430847168, 0.41884368658065796, -3.7308897972106934, -3.414062976837158, -3.8367884159088135, -0.9205548763275146]\n",
      "probs 1: [0.9995278120040894, 0.0003594527079258114, 5.668074663844891e-06, 7.780925443512388e-06, 5.09852179675363e-06, 9.417772525921464e-05]\n",
      "logits 2: [8.167972564697266, 2.218390703201294, -4.607939720153809, -4.245255947113037, -4.741819381713867, -1.198014259338379]\n",
      "probs 2: [0.9973052740097046, 0.002599904779344797, 2.8204599402670283e-06, 4.053510110679781e-06, 2.467043032083893e-06, 8.535553934052587e-05]\n",
      "logits 3: [-0.07396554946899414, 6.857104778289795, -3.7291007041931152, -3.349132537841797, -3.8588550090789795, -2.991471290588379]\n",
      "probs 3: [0.0009758673259057105, 0.9988871216773987, 2.5233983251382597e-05, 3.689806908369064e-05, 2.2163294488564134e-05, 5.276359661365859e-05]\n",
      "logits 4: [8.341974258422852, 0.362093985080719, -3.6979641914367676, -3.3827528953552246, -3.8028526306152344, -0.9136136770248413]\n",
      "probs 4: [0.9995429515838623, 0.0003421239380259067, 5.9009616961702704e-06, 8.087549758784007e-06, 5.313370820658747e-06, 9.553242853144184e-05]\n",
      "logits 5: [8.378085136413574, 0.8244061470031738, -3.9566779136657715, -3.6286120414733887, -4.069565296173096, -0.9734258651733398]\n",
      "probs 5: [0.9993749260902405, 0.0005238504963926971, 4.393484687170712e-06, 6.0993888837401755e-06, 3.924481916328659e-06, 8.677983714733273e-05]\n",
      "logits 6: [-1.6782922744750977, 6.677494525909424, -2.98637318611145, -2.632042407989502, -3.0974228382110596, -3.1887922286987305]\n",
      "probs 6: [0.00023491540923714638, 0.9995023012161255, 6.350666080834344e-05, 9.051139932125807e-05, 5.6831748224794865e-05, 5.186921771382913e-05]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [3, 0, 0, 1, 0, 0, 1]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [8.349299430847168, 0.41884368658065796, -3.7308897972106934, -3.414062976837158, -3.8367884159088135, -0.9205548763275146]\n",
      "probs 1: [0.9995278120040894, 0.0003594527079258114, 5.668074663844891e-06, 7.780925443512388e-06, 5.09852179675363e-06, 9.417772525921464e-05]\n",
      "logits 2: [8.167972564697266, 2.218390703201294, -4.607939720153809, -4.245255947113037, -4.741819381713867, -1.198014259338379]\n",
      "probs 2: [0.9973052740097046, 0.002599904779344797, 2.8204599402670283e-06, 4.053510110679781e-06, 2.467043032083893e-06, 8.535553934052587e-05]\n",
      "logits 3: [-0.07396554946899414, 6.857104778289795, -3.7291007041931152, -3.349132537841797, -3.8588550090789795, -2.991471290588379]\n",
      "probs 3: [0.0009758673259057105, 0.9988871216773987, 2.5233983251382597e-05, 3.689806908369064e-05, 2.2163294488564134e-05, 5.276359661365859e-05]\n",
      "logits 4: [8.341974258422852, 0.362093985080719, -3.6979641914367676, -3.3827528953552246, -3.8028526306152344, -0.9136136770248413]\n",
      "probs 4: [0.9995429515838623, 0.0003421239380259067, 5.9009616961702704e-06, 8.087549758784007e-06, 5.313370820658747e-06, 9.553242853144184e-05]\n",
      "logits 5: [8.378085136413574, 0.8244061470031738, -3.9566779136657715, -3.6286120414733887, -4.069565296173096, -0.9734258651733398]\n",
      "probs 5: [0.9993749260902405, 0.0005238504963926971, 4.393484687170712e-06, 6.0993888837401755e-06, 3.924481916328659e-06, 8.677983714733273e-05]\n",
      "logits 6: [-1.6782922744750977, 6.677494525909424, -2.98637318611145, -2.632042407989502, -3.0974228382110596, -3.1887922286987305]\n",
      "probs 6: [0.00023491540923714638, 0.9995023012161255, 6.350666080834344e-05, 9.051139932125807e-05, 5.6831748224794865e-05, 5.186921771382913e-05]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [3, 0, 0, 1, 0, 0, 1]\n",
      "logits 0: [-5.055187225341797, -2.022620677947998, 2.971548080444336, 3.0489652156829834, 3.0374908447265625, -2.437302589416504]\n",
      "probs 0: [0.00010335062688682228, 0.0021445699967443943, 0.31643176078796387, 0.3419021964073181, 0.3380015194416046, 0.0014165958855301142]\n",
      "logits 1: [8.349299430847168, 0.41884368658065796, -3.7308897972106934, -3.414062976837158, -3.8367884159088135, -0.9205548763275146]\n",
      "probs 1: [0.9995278120040894, 0.0003594527079258114, 5.668074663844891e-06, 7.780925443512388e-06, 5.09852179675363e-06, 9.417772525921464e-05]\n",
      "logits 2: [8.167972564697266, 2.218390703201294, -4.607939720153809, -4.245255947113037, -4.741819381713867, -1.198014259338379]\n",
      "probs 2: [0.9973052740097046, 0.002599904779344797, 2.8204599402670283e-06, 4.053510110679781e-06, 2.467043032083893e-06, 8.535553934052587e-05]\n",
      "logits 3: [-0.07396554946899414, 6.857104778289795, -3.7291007041931152, -3.349132537841797, -3.8588550090789795, -2.991471290588379]\n",
      "probs 3: [0.0009758673259057105, 0.9988871216773987, 2.5233983251382597e-05, 3.689806908369064e-05, 2.2163294488564134e-05, 5.276359661365859e-05]\n",
      "logits 4: [8.341974258422852, 0.362093985080719, -3.6979641914367676, -3.3827528953552246, -3.8028526306152344, -0.9136136770248413]\n",
      "probs 4: [0.9995429515838623, 0.0003421239380259067, 5.9009616961702704e-06, 8.087549758784007e-06, 5.313370820658747e-06, 9.553242853144184e-05]\n",
      "logits 5: [8.378085136413574, 0.8244061470031738, -3.9566779136657715, -3.6286120414733887, -4.069565296173096, -0.9734258651733398]\n",
      "probs 5: [0.9993749260902405, 0.0005238504963926971, 4.393484687170712e-06, 6.0993888837401755e-06, 3.924481916328659e-06, 8.677983714733273e-05]\n",
      "logits 6: [-1.6782922744750977, 6.677494525909424, -2.98637318611145, -2.632042407989502, -3.0974228382110596, -3.1887922286987305]\n",
      "probs 6: [0.00023491540923714638, 0.9995023012161255, 6.350666080834344e-05, 9.051139932125807e-05, 5.6831748224794865e-05, 5.186921771382913e-05]\n"
     ]
    }
   ],
   "source": [
    "num_layers = 2\n",
    "d_model = 3\n",
    "nhead = 3\n",
    "dim_ff = 2\n",
    "epochs = 500\n",
    "base_model = train_model(vocab_size, seq_len, epochs, batch_size, d_model, nhead, num_layers, dim_ff, lr, device, verbose=True)\n",
    "model = rl_model(base_model, rl_batch_size=rl_batch_size, verbose=True, beta=2)\n",
    "test_model(base_model, batch_size, seq_len, vocab_size)\n",
    "test_model(model, batch_size, seq_len, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2cd634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_ones(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    rewards = (output_tokens == 1).mean(dim=1, dtype=float)\n",
    "    return rewards\n",
    "\n",
    "def max_zeros(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    rewards = (output_tokens == 0).mean(dim=1, dtype=float)\n",
    "    return rewards\n",
    "\n",
    "def max_same(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    rewards = torch.zeros(output_tokens.size(0), dtype=float, device=output_tokens.device)\n",
    "    for i in range(output_tokens.size(0)):\n",
    "        counts = torch.bincount(output_tokens[i])\n",
    "        rewards[i] = counts.max().item() / output_tokens.size(1)\n",
    "    return rewards\n",
    "\n",
    "def max_alternate(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Vectorized: count positions where adjacent tokens differ\n",
    "    diffs = (output_tokens[:, 1:] != output_tokens[:, :-1]).float()\n",
    "    rewards = diffs.mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_palindrome(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Vectorized: compare first half with reversed second half\n",
    "    T = output_tokens.size(1)\n",
    "    first_half = output_tokens[:, :T//2]\n",
    "    second_half = output_tokens[:, -T//2:].flip(dims=[1])\n",
    "    matches = (first_half == second_half).float()\n",
    "    rewards = matches.mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_ascending(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward sequences where each token >= previous token\n",
    "    ascending = (output_tokens[:, 1:] >= output_tokens[:, :-1]).float()\n",
    "    rewards = ascending.mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_descending(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward sequences where each token <= previous token\n",
    "    descending = (output_tokens[:, 1:] <= output_tokens[:, :-1]).float()\n",
    "    rewards = descending.mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_unique(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward diversity - fraction of unique tokens\n",
    "    rewards = torch.zeros(output_tokens.size(0), dtype=float, device=output_tokens.device)\n",
    "    for i in range(output_tokens.size(0)):\n",
    "        rewards[i] = torch.unique(output_tokens[i]).size(0) / output_tokens.size(1)\n",
    "    return rewards\n",
    "\n",
    "def max_even(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward even-valued tokens\n",
    "    rewards = (output_tokens % 2 == 0).float().mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_odd(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward odd-valued tokens\n",
    "    rewards = (output_tokens % 2 == 1).float().mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_runs(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward long runs of same token (minimize transitions)\n",
    "    transitions = (output_tokens[:, 1:] != output_tokens[:, :-1]).float()\n",
    "    rewards = 1.0 - transitions.mean(dim=1)\n",
    "    return rewards\n",
    "\n",
    "def max_boundary_match(output_tokens: torch.LongTensor):\n",
    "    # output_tokens: (B, T)\n",
    "    # Reward when first and last tokens match\n",
    "    rewards = (output_tokens[:, 0] == output_tokens[:, -1]).float()\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daa86a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27128\\2220080227.py:25: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1857.)\n",
      "  model_stds = model_probs[i][1:].std(dim=0)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_27128\\2220080227.py:26: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1857.)\n",
      "  base_model_stds = base_model_probs[i][1:].std(dim=0)\n",
      " 42%|████▏     | 423/1000 [158:02:32<131:55:41, 823.12s/it]   "
     ]
    }
   ],
   "source": [
    "reward_fns = [max_ones, max_zeros, max_same, max_alternate, max_palindrome, max_ascending, max_descending, max_unique, max_even, max_odd, max_runs, max_boundary_match]\n",
    "reward_fn_names = ['ones', 'zeros', 'same', 'alternate', 'palindrome', 'ascending', 'descending', 'unique', 'even', 'odd', 'runs', 'boundary_match']\n",
    "\n",
    "test = torch.tensor([[5]], device=device)\n",
    "model_probs = [torch.tensor([[0 for i in range(6)]], dtype=float, device=device) for _ in range(len(reward_fns))]\n",
    "base_model_probs = [torch.tensor([[0 for i in range(6)]], dtype=float, device=device) for _ in range(len(reward_fns))]\n",
    "\n",
    "def quick_test_model(model, model_probs):\n",
    "    model_logits = model(test)\n",
    "    p_m = torch.softmax(model_logits, dim=-1)\n",
    "    return torch.cat((model_probs, p_m[0, :, :]))\n",
    "\n",
    "beta=1\n",
    "\n",
    "for epoch in tqdm(range(1000)):\n",
    "    for i, reward_fn in enumerate(reward_fns):\n",
    "        base_model = train_model(batch_size=batch_size)\n",
    "        model = rl_model(base_model, rl_batch_size=rl_batch_size, beta=beta, reward_fn=reward_fn)\n",
    "\n",
    "        model_probs[i] = quick_test_model(model, model_probs[i])\n",
    "        base_model_probs[i] = quick_test_model(base_model, base_model_probs[i])\n",
    "\n",
    "        model_means = model_probs[i][1:].mean(dim=0)\n",
    "        base_model_means = base_model_probs[i][1:].mean(dim=0)\n",
    "        model_stds = model_probs[i][1:].std(dim=0)\n",
    "        base_model_stds = base_model_probs[i][1:].std(dim=0)\n",
    "\n",
    "        text = f'Epoch: {epoch+1}\\nModel mean:{model_means}\\nModel std:{model_stds}\\nBase Model means:{base_model_means}\\nBase Model stds:{base_model_stds}'\n",
    "        with open(f'{reward_fn_names[i]}_beta_{beta}_log_file.txt', 'w') as f:\n",
    "            f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d01c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_emb\n",
      "Parameter containing:\n",
      "tensor([[[ 0.4930, -0.2230, -0.1690],\n",
      "         [ 0.8037, -0.6332,  0.2778],\n",
      "         [ 0.8064, -0.2626,  0.0808],\n",
      "         [-1.0894, -0.2210,  0.1107],\n",
      "         [-0.5729, -0.3024,  0.0262],\n",
      "         [ 0.7611, -0.0107,  0.2603],\n",
      "         [-0.9652, -0.0672,  0.0034],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], device='cuda:0', requires_grad=True)\n",
      "embedding.weight\n",
      "Parameter containing:\n",
      "tensor([[-1.2440,  0.1865,  1.0439],\n",
      "        [ 0.1008,  0.5810,  1.3011],\n",
      "        [ 0.7975,  0.8791,  1.2768],\n",
      "        [ 2.5740,  1.5790, -1.6963],\n",
      "        [-1.3601, -0.9434,  3.0559],\n",
      "        [-0.6374, -0.5944, -1.0413]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.self_attn.in_proj_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.3988,  0.7636,  1.7770],\n",
      "        [-1.7054, -0.5856, -0.5206],\n",
      "        [-1.8437, -0.1521, -0.7063],\n",
      "        [ 0.0672, -1.9782,  0.0395],\n",
      "        [-1.1515, -0.1998,  1.6773],\n",
      "        [-1.3865,  1.8502,  0.5987],\n",
      "        [-0.1469, -0.9062,  0.9657],\n",
      "        [-1.3056,  0.5580, -0.0477],\n",
      "        [-1.2927, -0.4080,  0.0333]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.self_attn.in_proj_bias\n",
      "Parameter containing:\n",
      "tensor([ 0.7378, -1.0184, -1.0903, -0.0156,  0.0430, -0.0111, -0.2523,  0.3737,\n",
      "        -0.3762], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.1778,  1.0157,  0.4892],\n",
      "        [-0.0366, -1.0782, -0.7915],\n",
      "        [ 0.5903,  0.3984,  0.4664]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0076, -0.0464,  0.0625], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.linear1.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0515, -0.2208,  0.0666],\n",
      "        [-0.3052,  1.3887, -0.2881]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.linear1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.6421, -0.1266], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.linear2.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.1365, -0.4485],\n",
      "        [-0.4478,  0.7658],\n",
      "        [ 0.3188, -0.5956]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.linear2.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.1743,  0.0467, -0.1106], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.norm1.weight\n",
      "Parameter containing:\n",
      "tensor([0.9808, 0.7736, 1.8143], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.norm1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0044,  0.0366, -0.0504], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.norm2.weight\n",
      "Parameter containing:\n",
      "tensor([1.3211, 1.1118, 1.1791], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.0.norm2.bias\n",
      "Parameter containing:\n",
      "tensor([-1.0090,  0.5288,  0.2410], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.self_attn.in_proj_weight\n",
      "Parameter containing:\n",
      "tensor([[-0.2042, -0.5168,  1.0137],\n",
      "        [-0.4686,  1.5051, -0.4932],\n",
      "        [-0.8262,  1.9776, -0.5250],\n",
      "        [-1.0521,  0.1690, -0.5017],\n",
      "        [ 0.2190, -1.6116,  0.8752],\n",
      "        [ 1.2155, -1.0909,  0.3961],\n",
      "        [-0.0115, -0.4952,  0.4059],\n",
      "        [-0.3891,  0.3026,  0.1854],\n",
      "        [-0.6420,  0.0911, -0.8310]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.self_attn.in_proj_bias\n",
      "Parameter containing:\n",
      "tensor([ 4.2677e-02, -5.2210e-01, -4.1087e-01, -1.9369e-04, -1.8404e-03,\n",
      "        -1.8072e-03,  7.0290e-02,  2.8233e-01, -4.4917e-02], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "encoder.layers.1.self_attn.out_proj.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.2324,  0.4135,  0.2460],\n",
      "        [ 0.0541, -0.3346, -0.4225],\n",
      "        [ 0.0841,  0.2760,  0.3380]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.self_attn.out_proj.bias\n",
      "Parameter containing:\n",
      "tensor([-0.1026,  0.0639, -0.0013], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.linear1.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.0710, -0.2637,  0.0865],\n",
      "        [ 0.2146,  0.0402, -0.0241]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.linear1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.6240, -0.2719], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.linear2.weight\n",
      "Parameter containing:\n",
      "tensor([[ 0.2076, -0.2146],\n",
      "        [-0.4865,  0.1419],\n",
      "        [ 0.2920, -0.3872]], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.linear2.bias\n",
      "Parameter containing:\n",
      "tensor([-0.0066, -0.0247,  0.0687], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.norm1.weight\n",
      "Parameter containing:\n",
      "tensor([1.3192, 0.8117, 1.1507], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.norm1.bias\n",
      "Parameter containing:\n",
      "tensor([-0.8311, -0.0129,  0.4437], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.norm2.weight\n",
      "Parameter containing:\n",
      "tensor([1.5168, 2.0519, 2.3549], device='cuda:0', requires_grad=True)\n",
      "encoder.layers.1.norm2.bias\n",
      "Parameter containing:\n",
      "tensor([0.0038, 0.8777, 0.4577], device='cuda:0', requires_grad=True)\n",
      "head.weight\n",
      "Parameter containing:\n",
      "tensor([[-0.4458,  1.2981,  0.5122],\n",
      "        [-0.0076, -1.3663,  1.6598],\n",
      "        [ 0.8230,  0.3678, -1.3953],\n",
      "        [ 0.5740,  0.1304, -1.6025],\n",
      "        [ 1.2701,  0.7122, -0.9873],\n",
      "        [ 0.6207, -1.1702, -0.3900]], device='cuda:0', requires_grad=True)\n",
      "head.bias\n",
      "Parameter containing:\n",
      "tensor([ 0.2314,  0.2753, -0.7813, -0.5183, -0.8704, -0.4637], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in model.named_parameters():\n",
    "    print(p[0])\n",
    "    print(p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8249551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model param count: 220\n",
      "Model count by layer:\n",
      "('pos_emb', Parameter containing:\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.],\n",
      "         [0., 0., 0.]]], device='cuda:0', requires_grad=True))\n",
      "('embedding.weight', Parameter containing:\n",
      "tensor([[ 0.5798,  0.3730, -1.1778],\n",
      "        [ 1.0841, -0.7502, -0.1226],\n",
      "        [ 0.6569, -1.4457, -0.1741],\n",
      "        [-1.1094, -0.1093,  1.1265],\n",
      "        [-0.0614,  0.2181, -0.6663],\n",
      "        [ 0.4830,  2.2888,  0.1088]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.6913,  0.3412,  0.1481],\n",
      "        [ 0.2179,  0.6534, -0.4690],\n",
      "        [-0.4616, -0.5935, -0.1431],\n",
      "        [ 0.0079, -0.4998, -0.4548],\n",
      "        [ 0.6591,  0.0831,  0.1527],\n",
      "        [ 0.0903,  0.1182,  0.1404],\n",
      "        [ 0.4189, -0.2423,  0.4320],\n",
      "        [ 0.5616, -0.0173, -0.1032],\n",
      "        [ 0.2046,  0.5215,  0.3819]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1531, -0.4685, -0.1125],\n",
      "        [ 0.3967, -0.2014,  0.0407],\n",
      "        [-0.2779, -0.3816,  0.4053]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0180,  0.2735, -0.5773],\n",
      "        [-0.3906, -0.5494, -0.4490]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear1.bias', Parameter containing:\n",
      "tensor([-0.4654, -0.5022], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6070, -0.4845],\n",
      "        [-0.5402, -0.5093],\n",
      "        [ 0.3120,  0.3089]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.linear2.bias', Parameter containing:\n",
      "tensor([ 0.1570,  0.6002, -0.1089], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.0.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_weight', Parameter containing:\n",
      "tensor([[ 0.6913,  0.3412,  0.1481],\n",
      "        [ 0.2179,  0.6534, -0.4690],\n",
      "        [-0.4616, -0.5935, -0.1431],\n",
      "        [ 0.0079, -0.4998, -0.4548],\n",
      "        [ 0.6591,  0.0831,  0.1527],\n",
      "        [ 0.0903,  0.1182,  0.1404],\n",
      "        [ 0.4189, -0.2423,  0.4320],\n",
      "        [ 0.5616, -0.0173, -0.1032],\n",
      "        [ 0.2046,  0.5215,  0.3819]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.in_proj_bias', Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.weight', Parameter containing:\n",
      "tensor([[-0.1531, -0.4685, -0.1125],\n",
      "        [ 0.3967, -0.2014,  0.0407],\n",
      "        [-0.2779, -0.3816,  0.4053]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.self_attn.out_proj.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.weight', Parameter containing:\n",
      "tensor([[-0.0180,  0.2735, -0.5773],\n",
      "        [-0.3906, -0.5494, -0.4490]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear1.bias', Parameter containing:\n",
      "tensor([-0.4654, -0.5022], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.weight', Parameter containing:\n",
      "tensor([[ 0.6070, -0.4845],\n",
      "        [-0.5402, -0.5093],\n",
      "        [ 0.3120,  0.3089]], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.linear2.bias', Parameter containing:\n",
      "tensor([ 0.1570,  0.6002, -0.1089], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm1.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.weight', Parameter containing:\n",
      "tensor([1., 1., 1.], device='cuda:0', requires_grad=True))\n",
      "('encoder.layers.1.norm2.bias', Parameter containing:\n",
      "tensor([0., 0., 0.], device='cuda:0', requires_grad=True))\n",
      "('head.weight', Parameter containing:\n",
      "tensor([[ 0.3185,  0.5560, -0.3257],\n",
      "        [ 0.2298,  0.0999, -0.1340],\n",
      "        [ 0.0347,  0.4755,  0.0544],\n",
      "        [ 0.3927, -0.5542, -0.5075],\n",
      "        [-0.0362, -0.5021,  0.5162],\n",
      "        [ 0.2533, -0.4509, -0.0643]], device='cuda:0', requires_grad=True))\n",
      "('head.bias', Parameter containing:\n",
      "tensor([ 0.4577, -0.3459,  0.2996,  0.0602, -0.0796,  0.5301], device='cuda:0',\n",
      "       requires_grad=True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.3768445551395416: 100%|██████████| 500/500 [00:17<00:00, 27.97it/s] \n",
      "loss=-0.0164  avg_reward=0.528 KL=0.000:   0%|          | 3/1000 [00:00<01:13, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0173  avg_reward=0.523 KL=0.000:   1%|          | 8/1000 [00:00<00:53, 18.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0342  avg_reward=0.541 KL=0.000:   1%|▏         | 14/1000 [00:00<00:46, 21.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0273  avg_reward=0.531 KL=0.000:   2%|▏         | 17/1000 [00:00<00:45, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0174  avg_reward=0.586 KL=0.001:   2%|▏         | 23/1000 [00:01<00:46, 21.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0269  avg_reward=0.554 KL=0.001:   3%|▎         | 27/1000 [00:01<00:44, 21.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0144  avg_reward=0.593 KL=0.001:   3%|▎         | 32/1000 [00:01<00:43, 22.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0248  avg_reward=0.557 KL=0.002:   4%|▍         | 38/1000 [00:01<00:42, 22.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0185  avg_reward=0.559 KL=0.002:   4%|▍         | 41/1000 [00:02<00:45, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 0, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0279  avg_reward=0.604 KL=0.002:   5%|▍         | 47/1000 [00:02<00:42, 22.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0259  avg_reward=0.590 KL=0.003:   5%|▌         | 53/1000 [00:02<00:40, 23.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0317  avg_reward=0.572 KL=0.003:   6%|▌         | 57/1000 [00:02<00:42, 22.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0341  avg_reward=0.598 KL=0.003:   6%|▋         | 63/1000 [00:02<00:40, 23.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0204  avg_reward=0.588 KL=0.004:   7%|▋         | 68/1000 [00:03<00:42, 22.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0208  avg_reward=0.601 KL=0.004:   7%|▋         | 74/1000 [00:03<00:38, 23.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0446  avg_reward=0.589 KL=0.004:   8%|▊         | 80/1000 [00:03<00:38, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0176  avg_reward=0.600 KL=0.004:   8%|▊         | 84/1000 [00:03<00:39, 23.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0232  avg_reward=0.606 KL=0.005:   9%|▉         | 89/1000 [00:04<00:39, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 1, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0489  avg_reward=0.604 KL=0.005:   9%|▉         | 93/1000 [00:04<00:42, 21.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0497  avg_reward=0.609 KL=0.005:  10%|▉         | 99/1000 [00:04<00:39, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0491  avg_reward=0.627 KL=0.005:  10%|█         | 105/1000 [00:04<00:38, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0450  avg_reward=0.629 KL=0.006:  11%|█         | 110/1000 [00:04<00:37, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0324  avg_reward=0.623 KL=0.006:  12%|█▏        | 116/1000 [00:05<00:36, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0526  avg_reward=0.606 KL=0.007:  12%|█▏        | 122/1000 [00:05<00:38, 22.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0351  avg_reward=0.614 KL=0.007:  13%|█▎        | 126/1000 [00:05<00:38, 22.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0458  avg_reward=0.655 KL=0.007:  13%|█▎        | 132/1000 [00:05<00:36, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0407  avg_reward=0.650 KL=0.007:  14%|█▍        | 138/1000 [00:06<00:35, 24.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0395  avg_reward=0.644 KL=0.008:  14%|█▍        | 143/1000 [00:06<00:37, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 1, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0479  avg_reward=0.665 KL=0.008:  15%|█▍        | 149/1000 [00:06<00:35, 24.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0450  avg_reward=0.640 KL=0.008:  16%|█▌        | 155/1000 [00:06<00:35, 23.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0541  avg_reward=0.645 KL=0.009:  16%|█▌        | 161/1000 [00:07<00:35, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0481  avg_reward=0.671 KL=0.009:  17%|█▋        | 167/1000 [00:07<00:35, 23.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0354  avg_reward=0.642 KL=0.010:  17%|█▋        | 170/1000 [00:07<00:37, 22.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0585  avg_reward=0.652 KL=0.009:  18%|█▊        | 176/1000 [00:07<00:34, 23.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0428  avg_reward=0.671 KL=0.010:  18%|█▊        | 182/1000 [00:08<00:33, 24.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0410  avg_reward=0.654 KL=0.011:  19%|█▉        | 188/1000 [00:08<00:33, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0464  avg_reward=0.653 KL=0.011:  19%|█▉        | 192/1000 [00:08<00:34, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0333  avg_reward=0.706 KL=0.010:  20%|█▉        | 198/1000 [00:08<00:34, 23.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 5, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0488  avg_reward=0.677 KL=0.011:  20%|██        | 203/1000 [00:08<00:36, 22.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0804  avg_reward=0.671 KL=0.011:  21%|██        | 209/1000 [00:09<00:34, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 1, 1, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0664  avg_reward=0.669 KL=0.011:  21%|██▏       | 213/1000 [00:09<00:34, 23.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0538  avg_reward=0.684 KL=0.012:  22%|██▏       | 219/1000 [00:09<00:35, 21.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0457  avg_reward=0.684 KL=0.012:  22%|██▎       | 225/1000 [00:09<00:33, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0528  avg_reward=0.707 KL=0.012:  23%|██▎       | 230/1000 [00:10<00:33, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0518  avg_reward=0.691 KL=0.013:  24%|██▎       | 236/1000 [00:10<00:32, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0463  avg_reward=0.679 KL=0.013:  24%|██▍       | 240/1000 [00:10<00:32, 23.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0517  avg_reward=0.688 KL=0.013:  24%|██▍       | 245/1000 [00:10<00:34, 22.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 2, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0632  avg_reward=0.681 KL=0.014:  25%|██▌       | 251/1000 [00:11<00:32, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0666  avg_reward=0.721 KL=0.014:  26%|██▌       | 255/1000 [00:11<00:32, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0621  avg_reward=0.694 KL=0.015:  26%|██▌       | 260/1000 [00:11<00:32, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0589  avg_reward=0.709 KL=0.015:  26%|██▋       | 264/1000 [00:11<00:34, 21.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0471  avg_reward=0.690 KL=0.015:  27%|██▋       | 270/1000 [00:11<00:32, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0606  avg_reward=0.692 KL=0.015:  28%|██▊       | 275/1000 [00:12<00:31, 22.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0506  avg_reward=0.654 KL=0.016:  28%|██▊       | 281/1000 [00:12<00:30, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0755  avg_reward=0.684 KL=0.015:  28%|██▊       | 285/1000 [00:12<00:30, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0357  avg_reward=0.714 KL=0.017:  29%|██▉       | 291/1000 [00:12<00:30, 23.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 1, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0475  avg_reward=0.722 KL=0.016:  30%|██▉       | 296/1000 [00:13<00:29, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0560  avg_reward=0.724 KL=0.016:  30%|███       | 302/1000 [00:13<00:29, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0635  avg_reward=0.707 KL=0.017:  31%|███       | 308/1000 [00:13<00:28, 23.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0558  avg_reward=0.724 KL=0.017:  31%|███       | 312/1000 [00:13<00:29, 23.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0490  avg_reward=0.735 KL=0.017:  32%|███▏      | 318/1000 [00:13<00:29, 23.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0388  avg_reward=0.709 KL=0.018:  32%|███▏      | 324/1000 [00:14<00:28, 23.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0546  avg_reward=0.702 KL=0.019:  33%|███▎      | 329/1000 [00:14<00:28, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0461  avg_reward=0.705 KL=0.019:  34%|███▎      | 335/1000 [00:14<00:27, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0589  avg_reward=0.690 KL=0.018:  34%|███▍      | 341/1000 [00:14<00:28, 22.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0651  avg_reward=0.704 KL=0.018:  35%|███▍      | 347/1000 [00:15<00:27, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0596  avg_reward=0.753 KL=0.018:  35%|███▌      | 351/1000 [00:15<00:27, 23.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0466  avg_reward=0.726 KL=0.019:  36%|███▌      | 357/1000 [00:15<00:26, 23.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0639  avg_reward=0.722 KL=0.019:  36%|███▋      | 363/1000 [00:15<00:25, 24.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 1, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0528  avg_reward=0.721 KL=0.019:  37%|███▋      | 369/1000 [00:16<00:27, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0596  avg_reward=0.750 KL=0.019:  38%|███▊      | 375/1000 [00:16<00:26, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0559  avg_reward=0.720 KL=0.020:  38%|███▊      | 381/1000 [00:16<00:25, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0526  avg_reward=0.750 KL=0.020:  39%|███▊      | 386/1000 [00:16<00:25, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 0, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0702  avg_reward=0.741 KL=0.019:  39%|███▉      | 392/1000 [00:17<00:25, 23.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0577  avg_reward=0.740 KL=0.021:  40%|███▉      | 398/1000 [00:17<00:25, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0739  avg_reward=0.742 KL=0.020:  40%|████      | 402/1000 [00:17<00:25, 23.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0598  avg_reward=0.745 KL=0.020:  41%|████      | 407/1000 [00:17<00:25, 23.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0573  avg_reward=0.759 KL=0.020:  41%|████      | 411/1000 [00:17<00:26, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0544  avg_reward=0.723 KL=0.021:  42%|████▏     | 417/1000 [00:18<00:25, 22.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0706  avg_reward=0.755 KL=0.020:  42%|████▏     | 423/1000 [00:18<00:24, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0538  avg_reward=0.768 KL=0.021:  43%|████▎     | 428/1000 [00:18<00:25, 22.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0546  avg_reward=0.751 KL=0.023:  43%|████▎     | 434/1000 [00:18<00:24, 23.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0637  avg_reward=0.749 KL=0.022:  44%|████▍     | 438/1000 [00:19<00:25, 22.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0571  avg_reward=0.758 KL=0.021:  44%|████▍     | 443/1000 [00:19<00:23, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0634  avg_reward=0.752 KL=0.022:  45%|████▍     | 449/1000 [00:19<00:22, 24.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0456  avg_reward=0.777 KL=0.022:  46%|████▌     | 455/1000 [00:19<00:22, 24.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0657  avg_reward=0.777 KL=0.022:  46%|████▌     | 461/1000 [00:20<00:22, 24.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0790  avg_reward=0.755 KL=0.022:  47%|████▋     | 467/1000 [00:20<00:22, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0539  avg_reward=0.758 KL=0.023:  47%|████▋     | 473/1000 [00:20<00:21, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0588  avg_reward=0.761 KL=0.022:  48%|████▊     | 477/1000 [00:20<00:22, 23.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0576  avg_reward=0.776 KL=0.023:  48%|████▊     | 482/1000 [00:20<00:21, 23.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0718  avg_reward=0.748 KL=0.023:  49%|████▊     | 486/1000 [00:21<00:23, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0700  avg_reward=0.776 KL=0.023:  49%|████▉     | 492/1000 [00:21<00:21, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0496  avg_reward=0.770 KL=0.024:  50%|████▉     | 497/1000 [00:21<00:21, 23.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0548  avg_reward=0.762 KL=0.023:  50%|█████     | 503/1000 [00:21<00:20, 24.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0648  avg_reward=0.780 KL=0.024:  51%|█████     | 509/1000 [00:22<00:20, 24.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0684  avg_reward=0.769 KL=0.024:  52%|█████▏    | 515/1000 [00:22<00:20, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0665  avg_reward=0.762 KL=0.026:  52%|█████▏    | 521/1000 [00:22<00:20, 23.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0818  avg_reward=0.786 KL=0.024:  53%|█████▎    | 527/1000 [00:22<00:19, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0725  avg_reward=0.778 KL=0.025:  53%|█████▎    | 533/1000 [00:23<00:20, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0551  avg_reward=0.775 KL=0.026:  54%|█████▎    | 537/1000 [00:23<00:21, 21.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 1, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0623  avg_reward=0.760 KL=0.026:  54%|█████▍    | 542/1000 [00:23<00:19, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 0, 1, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0625  avg_reward=0.768 KL=0.026:  55%|█████▍    | 548/1000 [00:23<00:18, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0833  avg_reward=0.773 KL=0.025:  55%|█████▌    | 554/1000 [00:24<00:19, 23.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0698  avg_reward=0.774 KL=0.025:  56%|█████▌    | 560/1000 [00:24<00:18, 23.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0740  avg_reward=0.787 KL=0.025:  56%|█████▋    | 564/1000 [00:24<00:18, 23.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 0, 1, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0678  avg_reward=0.792 KL=0.027:  57%|█████▋    | 570/1000 [00:24<00:18, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0551  avg_reward=0.792 KL=0.028:  58%|█████▊    | 576/1000 [00:24<00:17, 24.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0595  avg_reward=0.784 KL=0.027:  58%|█████▊    | 581/1000 [00:25<00:17, 24.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0713  avg_reward=0.780 KL=0.027:  59%|█████▊    | 587/1000 [00:25<00:17, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0693  avg_reward=0.801 KL=0.026:  59%|█████▉    | 593/1000 [00:25<00:17, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0735  avg_reward=0.795 KL=0.026:  60%|█████▉    | 597/1000 [00:25<00:16, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0576  avg_reward=0.795 KL=0.027:  60%|██████    | 603/1000 [00:26<00:16, 23.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 0, 1, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0872  avg_reward=0.772 KL=0.027:  61%|██████    | 608/1000 [00:26<00:18, 21.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0662  avg_reward=0.785 KL=0.027:  61%|██████    | 612/1000 [00:26<00:17, 22.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0836  avg_reward=0.774 KL=0.027:  62%|██████▏   | 618/1000 [00:26<00:16, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0647  avg_reward=0.774 KL=0.028:  62%|██████▏   | 623/1000 [00:27<00:16, 23.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 0, 0, 1, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0672  avg_reward=0.786 KL=0.028:  63%|██████▎   | 629/1000 [00:27<00:15, 23.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0504  avg_reward=0.791 KL=0.028:  64%|██████▎   | 635/1000 [00:27<00:15, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0699  avg_reward=0.799 KL=0.028:  64%|██████▍   | 639/1000 [00:27<00:15, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0755  avg_reward=0.796 KL=0.028:  64%|██████▍   | 645/1000 [00:27<00:14, 24.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0579  avg_reward=0.817 KL=0.027:  65%|██████▌   | 650/1000 [00:28<00:15, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0677  avg_reward=0.791 KL=0.028:  65%|██████▌   | 654/1000 [00:28<00:14, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0609  avg_reward=0.801 KL=0.029:  66%|██████▌   | 660/1000 [00:28<00:14, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0636  avg_reward=0.822 KL=0.028:  66%|██████▋   | 665/1000 [00:28<00:14, 22.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0726  avg_reward=0.790 KL=0.030:  67%|██████▋   | 671/1000 [00:29<00:14, 22.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0653  avg_reward=0.801 KL=0.030:  67%|██████▋   | 674/1000 [00:29<00:14, 22.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0637  avg_reward=0.790 KL=0.030:  68%|██████▊   | 680/1000 [00:29<00:14, 22.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0798  avg_reward=0.778 KL=0.029:  68%|██████▊   | 684/1000 [00:29<00:14, 22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0649  avg_reward=0.810 KL=0.030:  69%|██████▉   | 689/1000 [00:29<00:13, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0732  avg_reward=0.812 KL=0.030:  70%|██████▉   | 695/1000 [00:30<00:12, 23.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0721  avg_reward=0.778 KL=0.030:  70%|██████▉   | 698/1000 [00:30<00:13, 21.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0575  avg_reward=0.814 KL=0.031:  70%|███████   | 704/1000 [00:30<00:13, 22.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0742  avg_reward=0.800 KL=0.030:  71%|███████   | 710/1000 [00:30<00:12, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0726  avg_reward=0.791 KL=0.030:  71%|███████▏  | 714/1000 [00:30<00:12, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0689  avg_reward=0.797 KL=0.031:  72%|███████▏  | 719/1000 [00:31<00:12, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 5, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0794  avg_reward=0.803 KL=0.030:  72%|███████▎  | 725/1000 [00:31<00:11, 23.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0668  avg_reward=0.814 KL=0.031:  73%|███████▎  | 731/1000 [00:31<00:11, 24.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0577  avg_reward=0.827 KL=0.032:  74%|███████▎  | 735/1000 [00:31<00:11, 23.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 1, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0659  avg_reward=0.814 KL=0.032:  74%|███████▍  | 740/1000 [00:32<00:11, 22.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0683  avg_reward=0.806 KL=0.031:  75%|███████▍  | 746/1000 [00:32<00:10, 23.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0684  avg_reward=0.828 KL=0.030:  75%|███████▌  | 752/1000 [00:32<00:10, 22.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0688  avg_reward=0.804 KL=0.030:  76%|███████▌  | 756/1000 [00:32<00:10, 22.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0792  avg_reward=0.822 KL=0.030:  76%|███████▌  | 761/1000 [00:33<00:10, 21.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0863  avg_reward=0.813 KL=0.032:  77%|███████▋  | 767/1000 [00:33<00:10, 22.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0721  avg_reward=0.802 KL=0.033:  77%|███████▋  | 771/1000 [00:33<00:10, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0750  avg_reward=0.822 KL=0.033:  78%|███████▊  | 776/1000 [00:33<00:09, 23.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0527  avg_reward=0.811 KL=0.033:  78%|███████▊  | 781/1000 [00:33<00:09, 23.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0808  avg_reward=0.785 KL=0.032:  79%|███████▊  | 786/1000 [00:34<00:09, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0789  avg_reward=0.810 KL=0.032:  79%|███████▉  | 792/1000 [00:34<00:08, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0661  avg_reward=0.822 KL=0.031:  80%|███████▉  | 797/1000 [00:34<00:08, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0706  avg_reward=0.820 KL=0.033:  80%|████████  | 801/1000 [00:34<00:08, 22.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0644  avg_reward=0.812 KL=0.033:  81%|████████  | 807/1000 [00:35<00:08, 22.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0722  avg_reward=0.827 KL=0.033:  81%|████████▏ | 813/1000 [00:35<00:08, 23.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0671  avg_reward=0.824 KL=0.033:  82%|████████▏ | 819/1000 [00:35<00:07, 23.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0632  avg_reward=0.826 KL=0.034:  82%|████████▎ | 825/1000 [00:35<00:07, 23.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0812  avg_reward=0.808 KL=0.034:  83%|████████▎ | 830/1000 [00:36<00:07, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0768  avg_reward=0.813 KL=0.034:  84%|████████▎ | 836/1000 [00:36<00:06, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0636  avg_reward=0.824 KL=0.033:  84%|████████▍ | 842/1000 [00:36<00:06, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0785  avg_reward=0.832 KL=0.032:  85%|████████▍ | 848/1000 [00:36<00:06, 24.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0731  avg_reward=0.831 KL=0.033:  85%|████████▌ | 852/1000 [00:36<00:06, 21.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 1, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0787  avg_reward=0.818 KL=0.035:  86%|████████▌ | 858/1000 [00:37<00:06, 22.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0866  avg_reward=0.827 KL=0.034:  86%|████████▋ | 863/1000 [00:37<00:06, 22.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 4, 1, 1, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0836  avg_reward=0.817 KL=0.034:  87%|████████▋ | 869/1000 [00:37<00:05, 22.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0815  avg_reward=0.812 KL=0.034:  87%|████████▋ | 873/1000 [00:37<00:05, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0756  avg_reward=0.834 KL=0.033:  88%|████████▊ | 878/1000 [00:38<00:05, 23.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0770  avg_reward=0.817 KL=0.035:  88%|████████▊ | 884/1000 [00:38<00:04, 23.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0664  avg_reward=0.829 KL=0.034:  89%|████████▉ | 890/1000 [00:38<00:04, 23.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0709  avg_reward=0.824 KL=0.036:  89%|████████▉ | 894/1000 [00:38<00:05, 21.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 1, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0668  avg_reward=0.847 KL=0.035:  90%|████████▉ | 899/1000 [00:39<00:04, 22.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1, 0, 1, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0528  avg_reward=0.838 KL=0.035:  90%|█████████ | 905/1000 [00:39<00:04, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.1062  avg_reward=0.832 KL=0.033:  91%|█████████ | 909/1000 [00:39<00:04, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0688  avg_reward=0.828 KL=0.037:  91%|█████████▏| 914/1000 [00:39<00:03, 21.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 0, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0649  avg_reward=0.821 KL=0.036:  92%|█████████▏| 920/1000 [00:39<00:03, 23.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0637  avg_reward=0.830 KL=0.036:  93%|█████████▎| 926/1000 [00:40<00:03, 23.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0862  avg_reward=0.822 KL=0.035:  93%|█████████▎| 932/1000 [00:40<00:02, 23.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0724  avg_reward=0.821 KL=0.037:  94%|█████████▎| 935/1000 [00:40<00:02, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0667  avg_reward=0.829 KL=0.036:  94%|█████████▍| 941/1000 [00:40<00:02, 23.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0816  avg_reward=0.821 KL=0.037:  95%|█████████▍| 947/1000 [00:41<00:02, 23.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 0, 1, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0689  avg_reward=0.846 KL=0.037:  95%|█████████▌| 953/1000 [00:41<00:01, 23.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0766  avg_reward=0.832 KL=0.037:  96%|█████████▌| 959/1000 [00:41<00:01, 24.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 1, 1, 0, 1, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0815  avg_reward=0.824 KL=0.037:  96%|█████████▋| 965/1000 [00:41<00:01, 23.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0882  avg_reward=0.834 KL=0.037:  97%|█████████▋| 968/1000 [00:42<00:01, 23.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 1, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 0, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0755  avg_reward=0.825 KL=0.038:  97%|█████████▋| 974/1000 [00:42<00:01, 23.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0657  avg_reward=0.841 KL=0.037:  98%|█████████▊| 980/1000 [00:42<00:00, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 1, 1, 0, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0851  avg_reward=0.826 KL=0.037:  98%|█████████▊| 983/1000 [00:42<00:00, 21.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 0, 0, 0] Reward: 1.0\n",
      "[0, 4, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0853  avg_reward=0.834 KL=0.038:  99%|█████████▉| 989/1000 [00:42<00:00, 23.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 4, 0, 0, 0, 1, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0553  avg_reward=0.861 KL=0.038: 100%|█████████▉| 995/1000 [00:43<00:00, 23.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-0.0693  avg_reward=0.835 KL=0.038: 100%|██████████| 1000/1000 [00:43<00:00, 23.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "[0, 4, 1, 0, 1, 0, 0, 0] Reward: 1.0\n",
      "[0, 2, 1, 1, 0, 1, 1, 0] Reward: 1.0\n",
      "[0, 3, 0, 0, 1, 0, 0, 1] Reward: 0.0\n",
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [2, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [7.593873977661133, 0.07993529736995697, -1.3573397397994995, -1.3466355800628662, -2.4212021827697754, -5.511781215667725]\n",
      "probs 1: [0.9991480112075806, 0.0005449637537822127, 0.0001294693793170154, 0.00013086266699247062, 4.468252882361412e-05, 2.0319635041232686e-06]\n",
      "logits 2: [7.716328144073486, 1.9825786352157593, -2.5442287921905518, -2.3988771438598633, -3.598855495452881, -5.15521240234375]\n",
      "probs 2: [0.9966860413551331, 0.0032242052257061005, 3.48702487826813e-05, 4.032555079902522e-05, 1.2146091648901347e-05, 2.561648670962313e-06]\n",
      "logits 3: [1.000657081604004, 9.1657075881958, -5.728024959564209, -4.681591033935547, -5.863619804382324, 1.633225679397583]\n",
      "probs 3: [0.00028418886358849704, 0.9991793036460876, 3.399208310383983e-07, 9.679167760623386e-07, 2.9681746127607767e-07, 0.0005349682178348303]\n",
      "logits 4: [7.613133907318115, 0.22044943273067474, -1.4468399286270142, -1.4267507791519165, -2.5112786293029785, -5.49319314956665]\n",
      "probs 4: [0.9991081357002258, 0.0006151916459202766, 0.00011612237722147256, 0.00011847876157844439, 4.0053088014246896e-05, 2.030518544415827e-06]\n",
      "logits 5: [7.512270927429199, -0.4176539182662964, -1.0379791259765625, -1.059775948524475, -2.0981502532958984, -5.567443370819092]\n",
      "probs 5: [0.9991889595985413, 0.0003595215966925025, 0.0001933397725224495, 0.0001891711144708097, 6.697222852380946e-05, 2.085451569655561e-06]\n",
      "logits 6: [2.0629611015319824, 9.425020217895508, -6.078737258911133, -5.071163177490234, -6.341869831085205, 0.8890490531921387]\n",
      "probs 6: [0.0006343619315885007, 0.9991686344146729, 1.8468961116013816e-07, 5.058553256276355e-07, 1.419598874008443e-07, 0.00019611635070759803]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [2, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [7.593873977661133, 0.07993529736995697, -1.3573397397994995, -1.3466355800628662, -2.4212021827697754, -5.511781215667725]\n",
      "probs 1: [0.9991480112075806, 0.0005449637537822127, 0.0001294693793170154, 0.00013086266699247062, 4.468252882361412e-05, 2.0319635041232686e-06]\n",
      "logits 2: [7.716328144073486, 1.9825786352157593, -2.5442287921905518, -2.3988771438598633, -3.598855495452881, -5.15521240234375]\n",
      "probs 2: [0.9966860413551331, 0.0032242052257061005, 3.48702487826813e-05, 4.032555079902522e-05, 1.2146091648901347e-05, 2.561648670962313e-06]\n",
      "logits 3: [1.000657081604004, 9.1657075881958, -5.728024959564209, -4.681591033935547, -5.863619804382324, 1.633225679397583]\n",
      "probs 3: [0.00028418886358849704, 0.9991793036460876, 3.399208310383983e-07, 9.679167760623386e-07, 2.9681746127607767e-07, 0.0005349682178348303]\n",
      "logits 4: [7.613133907318115, 0.22044943273067474, -1.4468399286270142, -1.4267507791519165, -2.5112786293029785, -5.49319314956665]\n",
      "probs 4: [0.9991081357002258, 0.0006151916459202766, 0.00011612237722147256, 0.00011847876157844439, 4.0053088014246896e-05, 2.030518544415827e-06]\n",
      "logits 5: [7.512270927429199, -0.4176539182662964, -1.0379791259765625, -1.059775948524475, -2.0981502532958984, -5.567443370819092]\n",
      "probs 5: [0.9991889595985413, 0.0003595215966925025, 0.0001933397725224495, 0.0001891711144708097, 6.697222852380946e-05, 2.085451569655561e-06]\n",
      "logits 6: [2.0629611015319824, 9.425020217895508, -6.078737258911133, -5.071163177490234, -6.341869831085205, 0.8890490531921387]\n",
      "probs 6: [0.0006343619315885007, 0.9991686344146729, 1.8468961116013816e-07, 5.058553256276355e-07, 1.419598874008443e-07, 0.00019611635070759803]\n",
      "input : [5, 4, 0, 1, 1, 0, 1]\n",
      "preds : [2, 0, 0, 0, 0, 0, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [6.635586738586426, 6.544229507446289, -5.141482830047607, -4.598113536834717, -6.004680633544922, -3.258324146270752]\n",
      "probs 1: [0.5228030681610107, 0.47715798020362854, 4.0144127524399664e-06, 6.912008302606409e-06, 1.6933227016124874e-06, 2.639167541929055e-05]\n",
      "logits 2: [6.639150142669678, 6.537487983703613, -5.138000011444092, -4.595325946807861, -6.00172233581543, -3.2626185417175293]\n",
      "probs 2: [0.5253732204437256, 0.4745878577232361, 4.03382091462845e-06, 6.940599178051343e-06, 1.7006170764943818e-06, 2.6313851776649244e-05]\n",
      "logits 3: [6.6457037925720215, 6.52504301071167, -5.131566047668457, -4.590175151824951, -5.996254920959473, -3.270526885986328]\n",
      "probs 3: [0.5301080346107483, 0.46985307335853577, 4.0696900214243215e-06, 6.99333304510219e-06, 1.7140824866146431e-06, 2.616977144498378e-05]\n",
      "logits 4: [6.610186576843262, 6.591829776763916, -5.1660332679748535, -4.617737293243408, -6.025493144989014, -3.227822780609131]\n",
      "probs 4: [0.5045693516731262, 0.4953915476799011, 3.8776925066486e-06, 6.7095793383487035e-06, 1.6417803863078007e-06, 2.6935676942230202e-05]\n",
      "logits 5: [6.6222758293151855, 6.569275856018066, -5.154410362243652, -4.608451843261719, -6.015647888183594, -3.2423157691955566]\n",
      "probs 5: [0.5132268667221069, 0.4867340922355652, 3.942391685995972e-06, 6.805595603509573e-06, 1.6662058897054521e-06, 2.6679132133722305e-05]\n",
      "logits 6: [6.604674816131592, 6.602053642272949, -5.171295642852783, -4.621938705444336, -6.029946327209473, -3.22122859954834]\n",
      "probs 6: [0.5006356835365295, 0.499325156211853, 3.848423602903495e-06, 6.665999990218552e-06, 1.6307063788190135e-06, 2.7051188226323575e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [2, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [1.0477399826049805, 9.183418273925781, -5.747375011444092, -4.702201843261719, -5.888543128967285, 1.6017115116119385]\n",
      "probs 1: [0.00029266494675539434, 0.999196469783783, 3.275590074736101e-07, 9.31542501803051e-07, 2.844338098384469e-07, 0.0005092808860354125]\n",
      "logits 2: [1.08125638961792, 9.195667266845703, -5.760930061340332, -4.716681003570557, -5.906070232391357, 1.579192876815796]\n",
      "probs 2: [0.00029895929037593305, 0.9992076754570007, 3.192185147327109e-07, 9.069845532394538e-07, 2.760922939160082e-07, 0.0004918844206258655]\n",
      "logits 3: [7.679581165313721, 0.8534234762191772, -1.846341848373413, -1.7828644514083862, -2.910874605178833, -5.394062042236328]\n",
      "probs 3: [0.998738706111908, 0.0010836506262421608, 7.284439925570041e-05, 7.761830056551844e-05, 2.512321952963248e-05, 2.097205197060248e-06]\n",
      "logits 4: [1.949150562286377, 9.411088943481445, -6.049642562866211, -5.036876201629639, -6.298933982849121, 0.9720480442047119]\n",
      "probs 4: [0.0005740869673900306, 0.9992091059684753, 1.9281729635167721e-07, 5.308656341185269e-07, 1.5027271160761302e-07, 0.00021608636598102748]\n",
      "logits 5: [2.9547579288482666, 9.419233322143555, -6.236348628997803, -5.277998924255371, -6.609404563903809, 0.21153032779693604]\n",
      "probs 5: [0.0015552282566204667, 0.9983440637588501, 1.5854303114792856e-07, 4.1338373080179736e-07, 1.0917712955915704e-07, 0.00010009809193434194]\n",
      "logits 6: [7.68366003036499, 0.9065850973129272, -1.879623293876648, -1.8124197721481323, -2.943979263305664, -5.3845977783203125]\n",
      "probs 6: [0.9986904263496399, 0.0011381111107766628, 7.016974268481135e-05, 7.504745735786855e-05, 2.4205028239521198e-05, 2.108426315317047e-06]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [2, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [7.593873977661133, 0.07993529736995697, -1.3573397397994995, -1.3466355800628662, -2.4212021827697754, -5.511781215667725]\n",
      "probs 1: [0.9991480112075806, 0.0005449637537822127, 0.0001294693793170154, 0.00013086266699247062, 4.468252882361412e-05, 2.0319635041232686e-06]\n",
      "logits 2: [7.716328144073486, 1.9825786352157593, -2.5442287921905518, -2.3988771438598633, -3.598855495452881, -5.15521240234375]\n",
      "probs 2: [0.9966860413551331, 0.0032242052257061005, 3.48702487826813e-05, 4.032555079902522e-05, 1.2146091648901347e-05, 2.561648670962313e-06]\n",
      "logits 3: [1.000657081604004, 9.1657075881958, -5.728024959564209, -4.681591033935547, -5.863619804382324, 1.633225679397583]\n",
      "probs 3: [0.00028418886358849704, 0.9991793036460876, 3.399208310383983e-07, 9.679167760623386e-07, 2.9681746127607767e-07, 0.0005349682178348303]\n",
      "logits 4: [7.613133907318115, 0.22044943273067474, -1.4468399286270142, -1.4267507791519165, -2.5112786293029785, -5.49319314956665]\n",
      "probs 4: [0.9991081357002258, 0.0006151916459202766, 0.00011612237722147256, 0.00011847876157844439, 4.0053088014246896e-05, 2.030518544415827e-06]\n",
      "logits 5: [7.512270927429199, -0.4176539182662964, -1.0379791259765625, -1.059775948524475, -2.0981502532958984, -5.567443370819092]\n",
      "probs 5: [0.9991889595985413, 0.0003595215966925025, 0.0001933397725224495, 0.0001891711144708097, 6.697222852380946e-05, 2.085451569655561e-06]\n",
      "logits 6: [2.0629611015319824, 9.425020217895508, -6.078737258911133, -5.071163177490234, -6.341869831085205, 0.8890490531921387]\n",
      "probs 6: [0.0006343619315885007, 0.9991686344146729, 1.8468961116013816e-07, 5.058553256276355e-07, 1.419598874008443e-07, 0.00019611635070759803]\n",
      "input : [5, 4, 1, 0, 1, 0, 1]\n",
      "preds : [2, 0, 0, 0, 1, 1, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.5867127776145935, -6.600326061248779, 4.210480213165283, 4.172505855560303, 4.068892955780029, -0.8872502446174622]\n",
      "probs 0: [0.002900733845308423, 7.092981832101941e-06, 0.3514813780784607, 0.33838436007499695, 0.3050786256790161, 0.002147761406376958]\n",
      "logits 1: [6.635586738586426, 6.544229507446289, -5.141482830047607, -4.598113536834717, -6.004680633544922, -3.258324146270752]\n",
      "probs 1: [0.5228030681610107, 0.47715798020362854, 4.0144127524399664e-06, 6.912008302606409e-06, 1.6933227016124874e-06, 2.639167541929055e-05]\n",
      "logits 2: [6.657594203948975, 6.502326965332031, -5.119808197021484, -4.580755233764648, -5.9862518310546875, -3.284907817840576]\n",
      "probs 2: [0.5387181043624878, 0.46124306321144104, 4.135237759328447e-06, 7.0893793235882185e-06, 1.7386365698257578e-06, 2.590525218693074e-05]\n",
      "logits 3: [6.6517767906188965, 6.51346492767334, -5.125575542449951, -4.585376739501953, -5.9911603927612305, -3.2778658866882324]\n",
      "probs 3: [0.5345021486282349, 0.4654589593410492, 4.103083483641967e-06, 7.042315701255575e-06, 1.7266002032556571e-06, 2.6035171686089598e-05]\n",
      "logits 4: [6.483736515045166, 6.817453384399414, -5.281304836273193, -4.709328651428223, -6.122305870056152, -3.0786561965942383]\n",
      "probs 4: [0.4173199236392975, 0.5826402902603149, 3.2432199077447876e-06, 5.746226179326186e-06, 1.3987317970531876e-06, 2.9347744202823378e-05]\n",
      "logits 5: [6.5420427322387695, 6.715681076049805, -5.229538440704346, -4.668313026428223, -6.079021453857422, -3.146902322769165]\n",
      "probs 5: [0.45668110251426697, 0.5432794094085693, 3.5259852211311227e-06, 6.180411219247617e-06, 1.5078375099619734e-06, 2.8298134566284716e-05]\n",
      "logits 6: [6.551670074462891, 6.698512077331543, -5.220767498016357, -4.6613450050354, -6.071656703948975, -3.158257484436035]\n",
      "probs 6: [0.4633370339870453, 0.536623477935791, 3.5743128137255553e-06, 6.253832452784991e-06, 1.5263567547663115e-06, 2.8114416636526585e-05]\n",
      "TinyTransformer(\n",
      "  (embedding): Embedding(6, 3)\n",
      "  (encoder): TransformerEncoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerEncoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=3, out_features=3, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=3, out_features=2, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2, out_features=3, bias=True)\n",
      "        (norm1): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((3,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (head): Linear(in_features=3, out_features=6, bias=True)\n",
      ")\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [2, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [1.1448168754577637, 9.468208312988281, -6.274038314819336, -4.240289688110352, -6.086235046386719, 1.2804054021835327]\n",
      "probs 1: [0.0002426445425953716, 0.9994781613349915, 1.4554673555267073e-07, 1.1123673857582617e-06, 1.7561612253302883e-07, 0.00027787889121100307]\n",
      "logits 2: [1.2639234066009521, 9.512595176696777, -6.3219499588012695, -4.293015003204346, -6.149233818054199, 1.2007601261138916]\n",
      "probs 2: [0.00026147291646339, 0.999491810798645, 1.3271612431253743e-07, 1.0094358913192991e-06, 1.5773692041420873e-07, 0.00024546810891479254]\n",
      "logits 3: [7.631012439727783, 0.11393671482801437, -1.097452998161316, -1.7281633615493774, -2.3696906566619873, -5.521312713623047]\n",
      "probs 3: [0.9991616010665894, 0.000543264439329505, 0.00016177502402570099, 8.609885117039084e-05, 4.532999446382746e-05, 1.93933874470531e-06]\n",
      "logits 4: [1.5207386016845703, 9.595675468444824, -6.41690731048584, -4.4009270668029785, -6.277403831481934, 1.026387095451355]\n",
      "probs 4: [0.00031108668190427125, 0.9994980096817017, 1.1107226072226695e-07, 8.339393957612629e-07, 1.2770009050200315e-07, 0.00018975241982843727]\n",
      "logits 5: [2.3746583461761475, 9.749736785888672, -6.651826858520508, -4.703857898712158, -6.6293864250183105, 0.42100849747657776]\n",
      "probs 5: [0.0006262292736209929, 0.9992844462394714, 7.526282530534445e-08, 5.279258061818837e-07, 7.697081372270986e-08, 8.877153595676646e-05]\n",
      "logits 6: [7.4783935546875, -0.7110212445259094, -0.5280436873435974, -1.3093383312225342, -1.8226118087768555, -5.580062389373779]\n",
      "probs 6: [0.9991438388824463, 0.00027733860770240426, 0.0003330247418489307, 0.00015246299153659493, 9.125416545430198e-05, 2.1301609649526654e-06]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [2, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [7.73984956741333, 1.0528165102005005, -1.7353909015655518, -2.1871683597564697, -2.972688674926758, -5.406020164489746]\n",
      "probs 1: [0.9986051917076111, 0.0012452375376597047, 7.662122516194358e-05, 4.876908133155666e-05, 2.223298724857159e-05, 1.950809746631421e-06]\n",
      "logits 2: [7.480946063995361, 4.769039630889893, -4.153000831604004, -3.816211700439453, -5.150702476501465, -4.434670448303223]\n",
      "probs 2: [0.937698245048523, 0.06227261200547218, 8.308143151225522e-06, 1.1635097507678438e-05, 3.063427811866859e-06, 6.268684501264943e-06]\n",
      "logits 3: [1.3581852912902832, 9.545084953308105, -6.358123779296875, -4.333536148071289, -6.197489261627197, 1.1371759176254272]\n",
      "probs 3: [0.00027813564520329237, 0.999497652053833, 1.239098992300569e-07, 9.383680890096002e-07, 1.455018292517707e-07, 0.00022298371186479926]\n",
      "logits 4: [7.574374198913574, -0.22780543565750122, -0.862598717212677, -1.5564558506011963, -2.1450538635253906, -5.550566673278809]\n",
      "probs 4: [0.999204695224762, 0.0004085176042281091, 0.00021653284784406424, 0.00010818957525771111, 6.005656541674398e-05, 1.993265186683857e-06]\n",
      "logits 5: [7.582779884338379, -0.18041521310806274, -0.8952521681785583, -1.5804170370101929, -2.1763713359832764, -5.546921253204346]\n",
      "probs 5: [0.9992029070854187, 0.0004247573669999838, 0.00020782180945388973, 0.00010474371811142191, 5.771757059847005e-05, 1.9837946183542954e-06]\n",
      "logits 6: [3.2406187057495117, 9.712767601013184, -6.762272834777832, -4.922704219818115, -6.869026184082031, -0.23335453867912292]\n",
      "probs 6: [0.0015434393426403403, 0.9984081387519836, 6.986971357036964e-08, 4.397477937345684e-07, 6.279515929463741e-08, 4.783680196851492e-05]\n",
      "input : [5, 3, 0, 0, 1, 0, 0]\n",
      "preds : [2, 0, 0, 1, 0, 0, 1]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [7.73984956741333, 1.0528165102005005, -1.7353909015655518, -2.1871683597564697, -2.972688674926758, -5.406020164489746]\n",
      "probs 1: [0.9986051917076111, 0.0012452375376597047, 7.662122516194358e-05, 4.876908133155666e-05, 2.223298724857159e-05, 1.950809746631421e-06]\n",
      "logits 2: [7.480946063995361, 4.769039630889893, -4.153000831604004, -3.816211700439453, -5.150702476501465, -4.434670448303223]\n",
      "probs 2: [0.937698245048523, 0.06227261200547218, 8.308143151225522e-06, 1.1635097507678438e-05, 3.063427811866859e-06, 6.268684501264943e-06]\n",
      "logits 3: [1.3581852912902832, 9.545084953308105, -6.358123779296875, -4.333536148071289, -6.197489261627197, 1.1371759176254272]\n",
      "probs 3: [0.00027813564520329237, 0.999497652053833, 1.239098992300569e-07, 9.383680890096002e-07, 1.455018292517707e-07, 0.00022298371186479926]\n",
      "logits 4: [7.574374198913574, -0.22780543565750122, -0.862598717212677, -1.5564558506011963, -2.1450538635253906, -5.550566673278809]\n",
      "probs 4: [0.999204695224762, 0.0004085176042281091, 0.00021653284784406424, 0.00010818957525771111, 6.005656541674398e-05, 1.993265186683857e-06]\n",
      "logits 5: [7.582779884338379, -0.18041521310806274, -0.8952521681785583, -1.5804170370101929, -2.1763713359832764, -5.546921253204346]\n",
      "probs 5: [0.9992029070854187, 0.0004247573669999838, 0.00020782180945388973, 0.00010474371811142191, 5.771757059847005e-05, 1.9837946183542954e-06]\n",
      "logits 6: [3.2406187057495117, 9.712767601013184, -6.762272834777832, -4.922704219818115, -6.869026184082031, -0.23335453867912292]\n",
      "probs 6: [0.0015434393426403403, 0.9984081387519836, 6.986971357036964e-08, 4.397477937345684e-07, 6.279515929463741e-08, 4.783680196851492e-05]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [2, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [1.1448168754577637, 9.468208312988281, -6.274038314819336, -4.240289688110352, -6.086235046386719, 1.2804054021835327]\n",
      "probs 1: [0.0002426445425953716, 0.9994781613349915, 1.4554673555267073e-07, 1.1123673857582617e-06, 1.7561612253302883e-07, 0.00027787889121100307]\n",
      "logits 2: [1.2639234066009521, 9.512595176696777, -6.3219499588012695, -4.293015003204346, -6.149233818054199, 1.2007601261138916]\n",
      "probs 2: [0.00026147291646339, 0.999491810798645, 1.3271612431253743e-07, 1.0094358913192991e-06, 1.5773692041420873e-07, 0.00024546810891479254]\n",
      "logits 3: [7.631012439727783, 0.11393671482801437, -1.097452998161316, -1.7281633615493774, -2.3696906566619873, -5.521312713623047]\n",
      "probs 3: [0.9991616010665894, 0.000543264439329505, 0.00016177502402570099, 8.609885117039084e-05, 4.532999446382746e-05, 1.93933874470531e-06]\n",
      "logits 4: [1.5207386016845703, 9.595675468444824, -6.41690731048584, -4.4009270668029785, -6.277403831481934, 1.026387095451355]\n",
      "probs 4: [0.00031108668190427125, 0.9994980096817017, 1.1107226072226695e-07, 8.339393957612629e-07, 1.2770009050200315e-07, 0.00018975241982843727]\n",
      "logits 5: [2.3746583461761475, 9.749736785888672, -6.651826858520508, -4.703857898712158, -6.6293864250183105, 0.42100849747657776]\n",
      "probs 5: [0.0006262292736209929, 0.9992844462394714, 7.526282530534445e-08, 5.279258061818837e-07, 7.697081372270986e-08, 8.877153595676646e-05]\n",
      "logits 6: [7.4783935546875, -0.7110212445259094, -0.5280436873435974, -1.3093383312225342, -1.8226118087768555, -5.580062389373779]\n",
      "probs 6: [0.9991438388824463, 0.00027733860770240426, 0.0003330247418489307, 0.00015246299153659493, 9.125416545430198e-05, 2.1301609649526654e-06]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [2, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [1.1448168754577637, 9.468208312988281, -6.274038314819336, -4.240289688110352, -6.086235046386719, 1.2804054021835327]\n",
      "probs 1: [0.0002426445425953716, 0.9994781613349915, 1.4554673555267073e-07, 1.1123673857582617e-06, 1.7561612253302883e-07, 0.00027787889121100307]\n",
      "logits 2: [1.2639234066009521, 9.512595176696777, -6.3219499588012695, -4.293015003204346, -6.149233818054199, 1.2007601261138916]\n",
      "probs 2: [0.00026147291646339, 0.999491810798645, 1.3271612431253743e-07, 1.0094358913192991e-06, 1.5773692041420873e-07, 0.00024546810891479254]\n",
      "logits 3: [7.631012439727783, 0.11393671482801437, -1.097452998161316, -1.7281633615493774, -2.3696906566619873, -5.521312713623047]\n",
      "probs 3: [0.9991616010665894, 0.000543264439329505, 0.00016177502402570099, 8.609885117039084e-05, 4.532999446382746e-05, 1.93933874470531e-06]\n",
      "logits 4: [1.5207386016845703, 9.595675468444824, -6.41690731048584, -4.4009270668029785, -6.277403831481934, 1.026387095451355]\n",
      "probs 4: [0.00031108668190427125, 0.9994980096817017, 1.1107226072226695e-07, 8.339393957612629e-07, 1.2770009050200315e-07, 0.00018975241982843727]\n",
      "logits 5: [2.3746583461761475, 9.749736785888672, -6.651826858520508, -4.703857898712158, -6.6293864250183105, 0.42100849747657776]\n",
      "probs 5: [0.0006262292736209929, 0.9992844462394714, 7.526282530534445e-08, 5.279258061818837e-07, 7.697081372270986e-08, 8.877153595676646e-05]\n",
      "logits 6: [7.4783935546875, -0.7110212445259094, -0.5280436873435974, -1.3093383312225342, -1.8226118087768555, -5.580062389373779]\n",
      "probs 6: [0.9991438388824463, 0.00027733860770240426, 0.0003330247418489307, 0.00015246299153659493, 9.125416545430198e-05, 2.1301609649526654e-06]\n",
      "input : [5, 2, 1, 1, 0, 1, 1]\n",
      "preds : [2, 1, 1, 0, 1, 1, 0]\n",
      "reward: 0.0\n",
      "logits 0: [-0.9856691956520081, -6.801530361175537, 4.818791389465332, 3.7803092002868652, 4.437028884887695, -0.5349432229995728]\n",
      "probs 0: [0.0014743086649104953, 4.393313702166779e-06, 0.48914051055908203, 0.17315161228179932, 0.33391526341438293, 0.002313855569809675]\n",
      "logits 1: [1.1448168754577637, 9.468208312988281, -6.274038314819336, -4.240289688110352, -6.086235046386719, 1.2804054021835327]\n",
      "probs 1: [0.0002426445425953716, 0.9994781613349915, 1.4554673555267073e-07, 1.1123673857582617e-06, 1.7561612253302883e-07, 0.00027787889121100307]\n",
      "logits 2: [1.2639234066009521, 9.512595176696777, -6.3219499588012695, -4.293015003204346, -6.149233818054199, 1.2007601261138916]\n",
      "probs 2: [0.00026147291646339, 0.999491810798645, 1.3271612431253743e-07, 1.0094358913192991e-06, 1.5773692041420873e-07, 0.00024546810891479254]\n",
      "logits 3: [7.631012439727783, 0.11393671482801437, -1.097452998161316, -1.7281633615493774, -2.3696906566619873, -5.521312713623047]\n",
      "probs 3: [0.9991616010665894, 0.000543264439329505, 0.00016177502402570099, 8.609885117039084e-05, 4.532999446382746e-05, 1.93933874470531e-06]\n",
      "logits 4: [1.5207386016845703, 9.595675468444824, -6.41690731048584, -4.4009270668029785, -6.277403831481934, 1.026387095451355]\n",
      "probs 4: [0.00031108668190427125, 0.9994980096817017, 1.1107226072226695e-07, 8.339393957612629e-07, 1.2770009050200315e-07, 0.00018975241982843727]\n",
      "logits 5: [2.3746583461761475, 9.749736785888672, -6.651826858520508, -4.703857898712158, -6.6293864250183105, 0.42100849747657776]\n",
      "probs 5: [0.0006262292736209929, 0.9992844462394714, 7.526282530534445e-08, 5.279258061818837e-07, 7.697081372270986e-08, 8.877153595676646e-05]\n",
      "logits 6: [7.4783935546875, -0.7110212445259094, -0.5280436873435974, -1.3093383312225342, -1.8226118087768555, -5.580062389373779]\n",
      "probs 6: [0.9991438388824463, 0.00027733860770240426, 0.0003330247418489307, 0.00015246299153659493, 9.125416545430198e-05, 2.1301609649526654e-06]\n"
     ]
    }
   ],
   "source": [
    "from train_model import test_model\n",
    "beta = 1\n",
    "reward_fn = max_boundary_match\n",
    "base_model = train_model(batch_size=batch_size, verbose = True)\n",
    "model = rl_model(base_model, rl_batch_size=rl_batch_size, beta=beta, reward_fn=reward_fn, verbose=True)\n",
    "\n",
    "test_model(base_model, reward_fn=reward_fn)\n",
    "test_model(model, reward_fn=reward_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60b6ba0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1 - install (run once if you don't have plotly)\n",
    "# !pip install plotly\n",
    "\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from typing import Optional, Sequence, Union\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\" # \"iframe_connected\"   or \"notebook\", \"notebook_connected\", \"browser\"\n",
    "\n",
    "def plot_3d_points(\n",
    "    points: Union[np.ndarray, Sequence[Sequence[float]]],\n",
    "    labels: Optional[Union[Sequence[str], Sequence[int]]] = None,\n",
    "    title: Optional[str] = None,\n",
    "    marker_size: int = 5,\n",
    "    color_map: Optional[Sequence[str]] = None,\n",
    "    show_labels_as_text: bool = False,\n",
    "    hover_template: str = \"<b>%{text}</b><br>x=%{x:.3f}<br>y=%{y:.3f}<br>z=%{z:.3f}<extra></extra>\",\n",
    "    renderer: Optional[str] = None,\n",
    "    save_html: Optional[str] = None\n",
    "):\n",
    "    \"\"\"\n",
    "    points: N x 3 array-like (x,y,z)\n",
    "    labels: optional list of labels (strings or ints) length N. If provided, points are colored by label.\n",
    "    show_labels_as_text: if True, shows the label as on-plot text (can overlap).\n",
    "    renderer: optional plotly renderer (e.g. 'notebook', 'iframe', 'iframe_connected', 'notebook_connected')\n",
    "    save_html: if given, writes an interactive HTML file to that path\n",
    "    \"\"\"\n",
    "    pts = np.asarray(points)\n",
    "    if pts.ndim != 2 or pts.shape[1] != 3:\n",
    "        raise ValueError(\"points must be shape (N,3)\")\n",
    "\n",
    "    n = pts.shape[0]\n",
    "    x, y, z = pts[:,0], pts[:,1], pts[:,2]\n",
    "\n",
    "    if labels is None:\n",
    "        # single color\n",
    "        trace = go.Scatter3d(\n",
    "            x=x, y=y, z=z,\n",
    "            mode = \"markers+text\" if show_labels_as_text else \"markers\",\n",
    "            marker = dict(size=marker_size, opacity=0.9),\n",
    "            text = None,\n",
    "            hovertext = [f\"pt {i}\" for i in range(n)],\n",
    "            hovertemplate = hover_template\n",
    "        )\n",
    "        fig = go.Figure(trace)\n",
    "    else:\n",
    "        labels.append('origin')\n",
    "        x = np.append(x, 0)\n",
    "        y = np.append(y, 0)\n",
    "        z = np.append(z, 0)\n",
    "        labels_arr = np.asarray(labels)\n",
    "        # map labels to discrete colors\n",
    "        unique = np.unique(labels_arr)\n",
    "        # get a palette large enough\n",
    "        palette = list(px.colors.qualitative.Plotly)\n",
    "        if color_map is not None:\n",
    "            palette = list(color_map)\n",
    "        # repeat palette if necessary\n",
    "        while len(palette) < len(unique):\n",
    "            palette = palette + palette\n",
    "        color_for = {lab: palette[i] for i, lab in enumerate(unique)}\n",
    "        # build traces (one trace per label) to get clean legend & hover\n",
    "        traces = []\n",
    "        for lab in unique:\n",
    "            mask = labels_arr == lab\n",
    "            txt = labels_arr[mask].astype(str) if show_labels_as_text else None\n",
    "            hover = [f\"{lab} — idx {i}\" for i in np.where(mask)[0]]\n",
    "            traces.append(\n",
    "                go.Scatter3d(\n",
    "                    x = x[mask], y = y[mask], z = z[mask],\n",
    "                    mode = \"markers+text\" if show_labels_as_text else \"markers\",\n",
    "                    marker = dict(size=marker_size),\n",
    "                    name = str(lab),\n",
    "                    text = txt,\n",
    "                    hovertext = hover,\n",
    "                    hovertemplate = hover_template\n",
    "                )\n",
    "            )\n",
    "        fig = go.Figure(data=traces)\n",
    "\n",
    "    # layout: decent camera and axes labels\n",
    "    fig.update_layout(\n",
    "        title = title or \"\",\n",
    "        scene = dict(\n",
    "            xaxis_title=\"x\",\n",
    "            yaxis_title=\"y\",\n",
    "            zaxis_title=\"z\",\n",
    "            aspectmode=\"auto\",\n",
    "        ),\n",
    "        margin = dict(l=0, r=0, t=30, b=0),\n",
    "        legend = dict(itemsizing=\"constant\")\n",
    "    )\n",
    "\n",
    "    # set a nice initial camera angle (optional)\n",
    "    fig.update_layout(scene_camera=dict(\n",
    "        eye=dict(x=1.25, y=1.25, z=1.0)\n",
    "    ))\n",
    "\n",
    "    # show with requested renderer if provided\n",
    "    if renderer:\n",
    "        fig.show(renderer=renderer)\n",
    "    else:\n",
    "        fig.show()\n",
    "\n",
    "    if save_html:\n",
    "        fig.write_html(save_html, include_plotlyjs='cdn')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa6e142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_emb\n",
      "(1, 8, 3)\n",
      "embedding.weight\n",
      "(6, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight\n",
      "(9, 3)\n",
      "encoder.layers.0.self_attn.in_proj_bias\n",
      "(9,)\n",
      "encoder.layers.0.self_attn.out_proj.weight\n",
      "(3, 3)\n",
      "encoder.layers.0.self_attn.out_proj.bias\n",
      "(3,)\n",
      "encoder.layers.0.linear1.weight\n",
      "(2, 3)\n",
      "encoder.layers.0.linear1.bias\n",
      "(2,)\n",
      "encoder.layers.0.linear2.weight\n",
      "(3, 2)\n",
      "encoder.layers.0.linear2.bias\n",
      "(3,)\n",
      "encoder.layers.0.norm1.weight\n",
      "(3,)\n",
      "encoder.layers.0.norm1.bias\n",
      "(3,)\n",
      "encoder.layers.0.norm2.weight\n",
      "(3,)\n",
      "encoder.layers.0.norm2.bias\n",
      "(3,)\n",
      "encoder.layers.1.self_attn.in_proj_weight\n",
      "(9, 3)\n",
      "encoder.layers.1.self_attn.in_proj_bias\n",
      "(9,)\n",
      "encoder.layers.1.self_attn.out_proj.weight\n",
      "(3, 3)\n",
      "encoder.layers.1.self_attn.out_proj.bias\n",
      "(3,)\n",
      "encoder.layers.1.linear1.weight\n",
      "(2, 3)\n",
      "encoder.layers.1.linear1.bias\n",
      "(2,)\n",
      "encoder.layers.1.linear2.weight\n",
      "(3, 2)\n",
      "encoder.layers.1.linear2.bias\n",
      "(3,)\n",
      "encoder.layers.1.norm1.weight\n",
      "(3,)\n",
      "encoder.layers.1.norm1.bias\n",
      "(3,)\n",
      "encoder.layers.1.norm2.weight\n",
      "(3,)\n",
      "encoder.layers.1.norm2.bias\n",
      "(3,)\n",
      "head.weight\n",
      "(6, 3)\n",
      "head.bias\n",
      "(6,)\n"
     ]
    }
   ],
   "source": [
    "pts = {}\n",
    "for p in model.named_parameters():\n",
    "    print(p[0])\n",
    "    print(p[1].detach().cpu().numpy().shape)\n",
    "    pts[p[0]] = p[1].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "201b451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def tensor_to_points(name, t, num_heads=3, d_model=3):\n",
    "    \"\"\"\n",
    "    Convert a tensor into points of shape (n, 3).\n",
    "    Handles:\n",
    "      - pos_emb (1, seq, 3)\n",
    "      - embedding weights (vocab, 3)\n",
    "      - linear weights (out, in)\n",
    "      - biases (n,)\n",
    "      - MultiheadAttention QKV weights (9, 3) → per-head Q/K/V points\n",
    "      - MultiheadAttention QKV bias (9,) → per-head Q/K/V points\n",
    "    \"\"\"\n",
    "    t = t.detach().cpu()\n",
    "\n",
    "    # --- special case: MultiheadAttention QKV weights ---\n",
    "    if \"in_proj_weight\" in name:\n",
    "        # shape = (3 * d_model, d_model) = (9, 3)\n",
    "        assert t.shape == (3 * d_model, d_model)\n",
    "\n",
    "        # split Q, K, V along rows\n",
    "        Wq, Wk, Wv = t.chunk(3, dim=0)    # each (3, 3)\n",
    "\n",
    "        head_dim = d_model // num_heads   # here = 1\n",
    "\n",
    "        # reshape to (num_heads, head_dim, d_model) = (3, 1, 3)\n",
    "        Wq_h = Wq.view(num_heads, head_dim, d_model)\n",
    "        Wk_h = Wk.view(num_heads, head_dim, d_model)\n",
    "        Wv_h = Wv.view(num_heads, head_dim, d_model)\n",
    "\n",
    "        out = {}\n",
    "        for h in range(num_heads):\n",
    "            out[f\"{name}.Q.head{h}\"] = Wq_h[h].numpy()   # (1,3)\n",
    "            out[f\"{name}.K.head{h}\"] = Wk_h[h].numpy()   # (1,3)\n",
    "            out[f\"{name}.V.head{h}\"] = Wv_h[h].numpy()   # (1,3)\n",
    "        return out\n",
    "\n",
    "    # --- special case: MultiheadAttention QKV bias ---\n",
    "    if \"in_proj_bias\" in name:\n",
    "        # shape = (9,)\n",
    "        assert t.shape == (3 * d_model,)\n",
    "        bq, bk, bv = t.chunk(3, dim=0)    # each (3,)\n",
    "        out = {}\n",
    "        for part_name, vec in zip([\"Q\", \"K\", \"V\"], [bq, bk, bv]):\n",
    "            # reshape each bias vector (3,) as (3,1) then broadcast to (3,3)\n",
    "            # so each element becomes a separate 3D point\n",
    "            pts = vec.view(-1, 1).expand(-1, 3)\n",
    "            out[f\"{name}.{part_name}\"] = pts.numpy()     # (3,3)\n",
    "        return out\n",
    "\n",
    "    # --- normal 3D-shaped positional embeddings ---\n",
    "    if t.ndim == 3:\n",
    "        # expect (1, seq, 3)\n",
    "        assert t.shape[-1] == 3\n",
    "        return {name: t.reshape(-1, 3).numpy()}\n",
    "\n",
    "    # --- 2D matrices: weights ---\n",
    "    if t.ndim == 2:\n",
    "        out_dim, in_dim = t.shape\n",
    "        if in_dim == 3:\n",
    "            # each row is a 3D vector → (out_dim, 3)\n",
    "            return {name: t.numpy()}\n",
    "        elif out_dim == 3:\n",
    "            # transpose so rows become 3D\n",
    "            return {name: t.T.numpy()}\n",
    "        else:\n",
    "            # flatten weird shapes into 3D by grouping triples\n",
    "            flat = t.flatten()\n",
    "            n = flat.numel() // 3\n",
    "            return {name: flat[:3*n].view(n, 3).numpy()}\n",
    "\n",
    "    # --- 1D tensors: biases or norm weights ---\n",
    "    if t.ndim == 1:\n",
    "        if t.numel() == 3:\n",
    "            # (3,) → (1,3)\n",
    "            return {name: t.view(1,3).numpy()}\n",
    "        else:\n",
    "            # turn N numbers into N 3D points by repeating each scalar 3 times\n",
    "            pts = t.view(-1, 1).expand(-1, 3)   # (N,3)\n",
    "            return {name: pts.numpy()}\n",
    "\n",
    "    raise ValueError(f\"Don't know how to convert tensor {name} with shape {t.shape}\")\n",
    "\n",
    "\n",
    "def extract_all_points(model, num_heads=3, d_model=3):\n",
    "    \"\"\"\n",
    "    Walks every named parameter and buffer in the model,\n",
    "    converting them to 3D point clouds.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # named parameters\n",
    "    for name, p in model.named_parameters():\n",
    "        out = tensor_to_points(name, p, num_heads=num_heads, d_model=d_model)\n",
    "        results.update(out)\n",
    "\n",
    "    # named buffers (e.g. pos_emb)\n",
    "    for name, b in model.named_buffers():\n",
    "        out = tensor_to_points(name, b, num_heads=num_heads, d_model=d_model)\n",
    "        results.update(out)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94fd33b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_emb: model pts=(8, 3), base_model pts=(8, 3)\n",
      "embedding.weight: model pts=(6, 3), base_model pts=(6, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.Q.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.K.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.V.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.Q.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.K.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.V.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.Q.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.K.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight.V.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.self_attn.in_proj_bias.Q: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.0.self_attn.in_proj_bias.K: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.0.self_attn.in_proj_bias.V: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.0.self_attn.out_proj.weight: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.0.self_attn.out_proj.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.linear1.weight: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.0.linear1.bias: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.0.linear2.weight: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.0.linear2.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.norm1.weight: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.norm1.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.norm2.weight: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.0.norm2.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.Q.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.K.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.V.head0: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.Q.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.K.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.V.head1: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.Q.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.K.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_weight.V.head2: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.self_attn.in_proj_bias.Q: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.1.self_attn.in_proj_bias.K: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.1.self_attn.in_proj_bias.V: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.1.self_attn.out_proj.weight: model pts=(3, 3), base_model pts=(3, 3)\n",
      "encoder.layers.1.self_attn.out_proj.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.linear1.weight: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.1.linear1.bias: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.1.linear2.weight: model pts=(2, 3), base_model pts=(2, 3)\n",
      "encoder.layers.1.linear2.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.norm1.weight: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.norm1.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.norm2.weight: model pts=(1, 3), base_model pts=(1, 3)\n",
      "encoder.layers.1.norm2.bias: model pts=(1, 3), base_model pts=(1, 3)\n",
      "head.weight: model pts=(6, 3), base_model pts=(6, 3)\n",
      "head.bias: model pts=(6, 3), base_model pts=(6, 3)\n",
      "pos_emb (1, 8, 3)\n",
      "embedding.weight (6, 3)\n",
      "encoder.layers.0.self_attn.in_proj_weight (9, 3)\n",
      "encoder.layers.0.self_attn.in_proj_bias (9,)\n",
      "encoder.layers.0.self_attn.out_proj.weight (3, 3)\n",
      "encoder.layers.0.self_attn.out_proj.bias (3,)\n",
      "encoder.layers.0.linear1.weight (2, 3)\n",
      "encoder.layers.0.linear1.bias (2,)\n",
      "encoder.layers.0.linear2.weight (3, 2)\n",
      "encoder.layers.0.linear2.bias (3,)\n",
      "encoder.layers.0.norm1.weight (3,)\n",
      "encoder.layers.0.norm1.bias (3,)\n",
      "encoder.layers.0.norm2.weight (3,)\n",
      "encoder.layers.0.norm2.bias (3,)\n",
      "encoder.layers.1.self_attn.in_proj_weight (9, 3)\n",
      "encoder.layers.1.self_attn.in_proj_bias (9,)\n",
      "encoder.layers.1.self_attn.out_proj.weight (3, 3)\n",
      "encoder.layers.1.self_attn.out_proj.bias (3,)\n",
      "encoder.layers.1.linear1.weight (2, 3)\n",
      "encoder.layers.1.linear1.bias (2,)\n",
      "encoder.layers.1.linear2.weight (3, 2)\n",
      "encoder.layers.1.linear2.bias (3,)\n",
      "encoder.layers.1.norm1.weight (3,)\n",
      "encoder.layers.1.norm1.bias (3,)\n",
      "encoder.layers.1.norm2.weight (3,)\n",
      "encoder.layers.1.norm2.bias (3,)\n",
      "head.weight (6, 3)\n",
      "head.bias (6,)\n"
     ]
    }
   ],
   "source": [
    "all_pts_model = extract_all_points(model, num_heads=model.nhead, d_model=model.d_model)\n",
    "all_pts_base_model = extract_all_points(base_model, num_heads=base_model.nhead, d_model=base_model.d_model) \n",
    "for key in all_pts_model.keys():\n",
    "    print(f\"{key}: model pts={all_pts_model[key].shape}, base_model pts={all_pts_base_model[key].shape}\")\n",
    "\n",
    "for layer in model.named_parameters():\n",
    "    print(layer[0], layer[1].detach().cpu().numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79559bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[[ 1.2978913   0.77315223 -0.46048418]\n",
      " [-1.0961275   1.5237862  -0.35797852]\n",
      " [-0.31867623 -1.1218554   0.9555952 ]\n",
      " [-0.20730558 -0.9290279   1.0864348 ]\n",
      " [-0.71706647 -1.4376966   0.59803325]\n",
      " [-0.56169474  0.3174633   0.7844257 ]]\n",
      "[[ 1.2978913   0.77315223 -0.46048418]\n",
      " [-1.0961275   1.5237862  -0.35797852]\n",
      " [-0.31867623 -1.1218554   0.9555952 ]\n",
      " [-0.20730558 -0.9290279   1.0864348 ]\n",
      " [-0.71706647 -1.4376966   0.59803325]\n",
      " [-0.56169474  0.3174633   0.7844257 ]]\n",
      "(12, 3)\n",
      "[[ 1.2978913   0.77315223 -0.46048418]\n",
      " [-1.0961275   1.5237862  -0.35797852]\n",
      " [-0.31867623 -1.1218554   0.9555952 ]\n",
      " [-0.20730558 -0.9290279   1.0864348 ]\n",
      " [-0.71706647 -1.4376966   0.59803325]\n",
      " [-0.56169474  0.3174633   0.7844257 ]\n",
      " [ 0.3175949   0.3175949   0.3175949 ]\n",
      " [ 0.46366155  0.46366155  0.46366155]\n",
      " [ 0.00154167  0.00154167  0.00154167]\n",
      " [ 0.26301378  0.26301378  0.26301378]\n",
      " [ 0.00249871  0.00249871  0.00249871]\n",
      " [-0.36047423 -0.36047423 -0.36047423]]\n",
      "(12, 3)\n",
      "['weight0', 'weight1', 'weight2', 'weight3', 'weight4', 'weight5', 'bias0', 'bias1', 'bias2', 'bias3', 'bias4', 'bias5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.3.0.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.3.0.min.js\" integrity=\"sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=\" crossorigin=\"anonymous\"></script>                <div id=\"86f22e3f-8385-4d9f-9c6e-0a55361d94e7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"86f22e3f-8385-4d9f-9c6e-0a55361d94e7\")) {                    Plotly.newPlot(                        \"86f22e3f-8385-4d9f-9c6e-0a55361d94e7\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias0 \\u2014 idx 6\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias0\",\"text\":[\"bias0\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgHlT1D8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgHlT1D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgHlT1D8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias1 \\u2014 idx 7\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias1\",\"text\":[\"bias1\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKGs3T8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKGs3T8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKGs3T8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias2 \\u2014 idx 8\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias2\",\"text\":[\"bias2\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAD5CWT8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAD5CWT8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAD5CWT8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias3 \\u2014 idx 9\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias3\",\"text\":[\"bias3\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwDfV0D8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwDfV0D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwDfV0D8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias4 \\u2014 idx 10\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias4\",\"text\":[\"bias4\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAICp4ZD8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAICp4ZD8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAICp4ZD8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias5 \\u2014 idx 11\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias5\",\"text\":[\"bias5\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgAIS178=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgAIS178=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgAIS178=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"origin \\u2014 idx 12\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"origin\",\"text\":[\"origin\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight0 \\u2014 idx 0\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight0\",\"text\":[\"weight0\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoCnE9D8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwKm96D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoJJ43b8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight1 \\u2014 idx 1\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight1\",\"text\":[\"weight1\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAL2J8b8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoG1h+D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwB7p1r8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight2 \\u2014 idx 2\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight2\",\"text\":[\"weight2\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAADFl1L8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoB7z8b8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAYDyU7j8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight3 \\u2014 idx 3\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight3\",\"text\":[\"weight3\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQP2Iyr8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwJi67b8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgAli8T8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight4 \\u2014 idx 4\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight4\",\"text\":[\"weight4\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAYDXy5r8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAIM4A978=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoBYj4z8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight5 \\u2014 idx 5\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight5\",\"text\":[\"weight5\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQGf54b8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoFFR1D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4AMa6T8=\"},\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}},\"aspectmode\":\"auto\",\"camera\":{\"eye\":{\"x\":1.25,\"y\":1.25,\"z\":1.0}}},\"margin\":{\"l\":0,\"r\":0,\"t\":30,\"b\":0},\"legend\":{\"itemsizing\":\"constant\"},\"title\":{\"text\":\"\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('86f22e3f-8385-4d9f-9c6e-0a55361d94e7');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        </script>\n",
       "        <script type=\"module\">import \"https://cdn.plot.ly/plotly-3.3.0.min\"</script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-3.3.0.min.js\" integrity=\"sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=\" crossorigin=\"anonymous\"></script>                <div id=\"87e744a0-87c6-4d43-a79d-2331582f3c38\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById(\"87e744a0-87c6-4d43-a79d-2331582f3c38\")) {                    Plotly.newPlot(                        \"87e744a0-87c6-4d43-a79d-2331582f3c38\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias0 \\u2014 idx 6\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias0\",\"text\":[\"bias0\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgDZs0z8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgDZs0z8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgDZs0z8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias1 \\u2014 idx 7\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias1\",\"text\":[\"bias1\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4NWI3j8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4NWI3j8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4NWI3j8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias2 \\u2014 idx 8\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias2\",\"text\":[\"bias2\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQFhsmD8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQFhsmD8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQFhsmD8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias3 \\u2014 idx 9\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias3\",\"text\":[\"bias3\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwCmcyz8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwCmcyz8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwCmcyz8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias4 \\u2014 idx 10\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias4\",\"text\":[\"bias4\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAB5Nqz8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAB5Nqz8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAB5Nqz8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"bias5 \\u2014 idx 11\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"bias5\",\"text\":[\"bias5\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKzI2r8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKzI2r8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgKzI2r8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"origin \\u2014 idx 12\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"origin\",\"text\":[\"origin\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAAAAAAA=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight0 \\u2014 idx 0\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight0\",\"text\":[\"weight0\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQBCw9D8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAgIl86D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4N\\u002f93L8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight1 \\u2014 idx 1\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight1\",\"text\":[\"weight1\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwLaH8b8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAH+d+D8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwM6Z178=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight2 \\u2014 idx 2\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight2\",\"text\":[\"weight2\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQOCA0r8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAYCpH8r8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAGNB7j8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight3 \\u2014 idx 3\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight3\",\"text\":[\"weight3\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAQLvAz78=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAIEsu7L8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAIDJx8D8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight4 \\u2014 idx 4\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight4\",\"text\":[\"weight4\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAA4GqS5b8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAYAHW978=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwDcr5T8=\"},\"type\":\"scatter3d\"},{\"hovertemplate\":\"\\u003cb\\u003e%{text}\\u003c\\u002fb\\u003e\\u003cbr\\u003ex=%{x:.3f}\\u003cbr\\u003ey=%{y:.3f}\\u003cbr\\u003ez=%{z:.3f}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"weight5 \\u2014 idx 5\"],\"marker\":{\"size\":8},\"mode\":\"markers+text\",\"name\":\"weight5\",\"text\":[\"weight5\"],\"x\":{\"dtype\":\"f8\",\"bdata\":\"AAAAAFGl4r8=\"},\"y\":{\"dtype\":\"f8\",\"bdata\":\"AAAAoKJO0z8=\"},\"z\":{\"dtype\":\"f8\",\"bdata\":\"AAAAwJmT6j8=\"},\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermap\":[{\"type\":\"scattermap\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"xaxis\":{\"title\":{\"text\":\"x\"}},\"yaxis\":{\"title\":{\"text\":\"y\"}},\"zaxis\":{\"title\":{\"text\":\"z\"}},\"aspectmode\":\"auto\",\"camera\":{\"eye\":{\"x\":1.25,\"y\":1.25,\"z\":1.0}}},\"margin\":{\"l\":0,\"r\":0,\"t\":30,\"b\":0},\"legend\":{\"itemsizing\":\"constant\"},\"title\":{\"text\":\"\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('87e744a0-87c6-4d43-a79d-2331582f3c38');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "for pt in all_pts_base_model.keys():\n",
    "    print(pt, all_pts_base_model[pt].shape)\n",
    "    print((all_pts_base_model[pt] - all_pts_model[pt]))\n",
    "'''\n",
    "    \n",
    "pt = 'head.'  # change this to visualize other parts of the model\n",
    "\n",
    "if 'encoder' or 'head' in pt:\n",
    "    pts_base = np.array([[]])\n",
    "    pts = np.array([[]])\n",
    "    for key in all_pts_model.keys():\n",
    "        if pt in key:\n",
    "            print(pts_base)\n",
    "            if pts_base.size == 0:\n",
    "                pts_base = all_pts_base_model[key]\n",
    "                pts = all_pts_model[key]\n",
    "                labels_base = [key[len(pt):] + '0']\n",
    "                labels = [key[len(pt):] + '0']\n",
    "                for i in range(all_pts_base_model[key].shape[0] - 1):\n",
    "                    labels_base.append(key[len(pt):] + str(i + 1))\n",
    "                    labels.append(key[len(pt):] + str(i + 1))\n",
    "            else:\n",
    "                pts_base = np.append(pts_base, all_pts_base_model[key], axis=0)\n",
    "                pts = np.append(pts, all_pts_model[key], axis=0)\n",
    "                print(pts_base.shape)\n",
    "                for i in range(all_pts_base_model[key].shape[0]):\n",
    "                    labels_base.append(key[len(pt):] + str(i))\n",
    "                    labels.append(key[len(pt):] + str(i))\n",
    "            print(pts_base)\n",
    "else:\n",
    "    pts_base = all_pts_base_model[pt]\n",
    "    pts = all_pts_model[pt]\n",
    "    labels_base = [str(i) for i in range(len(pts_base))]\n",
    "    labels = [str(i) for i in range(len(pts))]\n",
    "print(pts_base.shape)\n",
    "print(labels)\n",
    "plot_3d_points(pts_base, labels=labels_base, show_labels_as_text=True, marker_size=8, renderer='notebook_connected')   \n",
    "plot_3d_points(pts, labels=labels, show_labels_as_text=True, marker_size=8, renderer='notebook_connected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c746a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".toysimulatorvenve (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
